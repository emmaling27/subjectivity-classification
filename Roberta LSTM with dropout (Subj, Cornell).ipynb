{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Roberta LSTM with dropout (Subj, Cornell).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UVOdl3WqEbs9"},"source":["# Roberta with LSTM On Top\n","\n","Based on: https://github.com/prakashpandey9/Text-Classification-Pytorch\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bLQCd7QVWpZK","scrolled":false,"colab":{}},"source":["#!pip install transformers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LnhjV7zhmafJ","outputId":"7167deea-3b93-4dae-f56e-a67c623c63ed","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json, re\n","from tqdm import tqdm_notebook\n","from uuid import uuid4\n","# from google.colab import drive\n","from sklearn.model_selection import train_test_split\n","\n","## PyTorch Transformer\n","from transformers import RobertaModel, RobertaTokenizer\n","\n","## Torch Modules\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import device as device_\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","from torchtext import data\n","from torchtext import datasets\n","from torchtext.vocab import Vectors, GloVe\n","print(torch.__version__)\n","print(torch.cuda.is_available())\n","print(torch.version.cuda)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.2.0\n","True\n","10.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TAQ-od7CxvXH"},"source":["## Load Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5eqIHmo1x1cJ","colab":{}},"source":["# main training dataset\n","\n","cbert_train_url = 'https://raw.githubusercontent.com/lcassels/cbert_aug/develop/datasets/subj/train.tsv'\n","cbert_test_url = 'https://raw.githubusercontent.com/lcassels/cbert_aug/develop/datasets/subj/test.tsv'\n","\n","cbert_train = pd.read_csv(cbert_train_url, sep='\\t')\n","cbert_test = pd.read_csv(cbert_test_url, sep='\\t')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gTHuheUc_x_R","colab":{}},"source":["cbert_train, cbert_val = train_test_split(cbert_train, test_size=0.1, random_state=0, shuffle=True)\n","cbert_train.reset_index(inplace=True)\n","cbert_train.drop(columns=[\"index\"], inplace=True)\n","cbert_val.reset_index(inplace=True)\n","cbert_val.drop(columns=[\"index\"], inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"th3m5RNOAkO1","outputId":"2ee73bfa-3a5d-483d-edc9-96e0eb2e216b","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["cbert_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>two tedious acts light on great scares and a g...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>their daughter rachel cleans in a home for eld...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>nete's father moves in and puts even more stra...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>following ram dass down from his pedestal give...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>at dinner , his father asks him about his new ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label\n","0  two tedious acts light on great scares and a g...      0\n","1  their daughter rachel cleans in a home for eld...      1\n","2  nete's father moves in and puts even more stra...      1\n","3  following ram dass down from his pedestal give...      0\n","4  at dinner , his father asks him about his new ...      1"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oGAd1YEX8ltR"},"source":["## Pre-process Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W83GUNQEaX2N","colab":{}},"source":["def prepare_features(seq, max_seq_length = 200, \n","             zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n","    ''' seq: string, sequence of words\n","        output:\n","          1D list of tokens, if zero_pad then 200 tokens long, else variable.\n","    '''\n","    ## Tokenzine Input\n","    tokens_a = tokenizer.tokenize(seq)\n","\n","    ## Truncate\n","    if len(tokens_a) > max_seq_length - 2:\n","        tokens_a = tokens_a[0:(max_seq_length - 2)]\n","    ## Initialize Tokens\n","    tokens = []\n","    if include_CLS_token:\n","        tokens.append(tokenizer.cls_token)\n","    ## Add Tokens and separators\n","    for token in tokens_a:\n","        tokens.append(token)\n","\n","    if include_SEP_token:\n","        tokens.append(tokenizer.sep_token)\n","\n","    # adding sep token to end and padding up to max_seq_length - 1\n","\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    if zero_pad:\n","        while len(input_ids) < max_seq_length:\n","            input_ids.append(0)\n","\n","    return input_ids"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"idpL48wa0be-","colab":{}},"source":["class Intents(Dataset):\n","    def __init__(self, dataframe):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        \n","    def __getitem__(self, index):\n","        sentence = self.data.sentence[index]\n","        label = self.data.label[index]\n","        X  = torch.LongTensor(prepare_features(sentence, zero_pad=True))\n","        y = self.data.label[index]\n","        return X, y\n","    \n","    def __len__(self):\n","        return self.len"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IPn-6ZIaVVlE"},"source":["## Model\n","\n","Adapted from https://github.com/prakashpandey9/Text-Classification-Pytorch."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ATizsJKouBqD","colab":{}},"source":["learning_rate = 2e-5\n","batch_size = 16\n","output_size = 2\n","hidden_size = 256\n","# Roberta embedding length\n","embedding_length = 768\n","\n","loss_fn = F.cross_entropy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U2C7vJ179fup","colab":{}},"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","robertaModel = RobertaModel.from_pretrained('roberta-base').cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4VrV76YsdtE4","colab":{}},"source":["class LSTMClassifierRoberta(nn.Module):\n","  def __init__(self, batch_size, output_size, hidden_size, embedding_length = embedding_length):\n","    super(LSTMClassifierRoberta, self).__init__()\n","    \"\"\"\n","\t\tArguments\n","\t\t---------\n","\t\tbatch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n","\t\toutput_size : 2 = (pos, neg)\n","\t\thidden_size : Size of the hidden_state of the LSTM\n","\t\tembedding_length : Embeddding dimension of GloVe word embeddings\t\t\n","\t\t\"\"\"\n","\t\t\n","    self.batch_size = batch_size\n","    self.output_size = output_size\n","    self.hidden_size = hidden_size\n","    self.embedding_length = embedding_length\n","\t\t\n","    self.dropout = nn.Dropout(.5)\n","    self.lstm = nn.LSTM(embedding_length, hidden_size)\n","    self.label = nn.Linear(hidden_size, output_size)\n","\n","    # alternative structure to reduce dimension\n","    # self.linear = nn.Linear(embedding_length, 512)\n","    # self.lstm = nn.LSTM(512, hidden_size)\n","    # self.label = nn.Linear(hidden_size, output_size)\n","\n","  def forward(self, input_sentence, batch_size=None):\n","    \"\"\" \n","    Parameters\n","    ----------\n","    input_sentence: input_sentence of shape = (batch_size, max_seq_len). Already tokenized and zero padded.\n","    batch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\n","\n","    Returns\n","    -------\n","    Output of the linear layer containing logits for positive & negative class which receives its input as the final_hidden_state of the LSTM\n","    final_output.shape = (batch_size, output_size)\n","    \"\"\"\n","\n","    ''' Here we will map all the indexes present in the input sequence to the corresponding word vector using our pre-trained word_embedddins.'''\n","\n","    # only place to cuda after getting embedding because Roberta model except it on device.\n","    input_x = robertaModel(input_sentence.cuda())[0].cuda()\n","\n","    # this line is not necessary and not sure what difference it makes:\n","    # input_x.requires_grad_ = False\n","\n","    input_x = input_x.permute(1, 0, 2) # input_x.size() = (max_seq_len, batch_size, embedding_length)\n","\n","    input_x = self.dropout(input_x)\n","\n","    if batch_size is None:\n","      h_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) # Initial hidden state of the LSTM\n","      c_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) # Initial cell state of the LSTM\n","    else:\n","      h_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n","      c_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n","\n","    # like above, uncomment this to reduce dimensionality\n","    # input_x = self.linear(input_x)\n","\n","    output, (final_hidden_state, final_cell_state) = self.lstm(input_x, (h_0, c_0))\n","\n","    final_output = self.label(final_hidden_state[-1]) # final_hidden_state.size() = (1, batch_size, hidden_size) & final_output.size() = (batch_size, output_size)\n","    return final_output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZBOMBgGSuEuc"},"source":["##Set Up Training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ujGNgt3CuBP2","colab":{}},"source":["def clip_gradient(model, clip_value):\n","    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n","    for p in params:\n","        p.grad.data.clamp_(-clip_value, clip_value)\n","\n","def train_model(model, train_iter, epoch):\n","    total_epoch_loss = 0\n","    total_epoch_acc = 0\n","    model.cuda()\n","    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n","    steps = 0\n","    model.train()\n","    for idx, batch in enumerate(train_iter):\n","        text = batch[0]\n","        target = batch[1]\n","\n","        target = torch.autograd.Variable(target).long()\n","\n","        if torch.cuda.is_available():\n","            target = target.cuda()\n","\n","        optim.zero_grad()\n","        prediction = model(text)\n","        loss = loss_fn(prediction, target)\n","        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n","\n","        acc = 100.0 * num_corrects/batch_size\n","        loss.backward()\n","        clip_gradient(model, 1e-1)\n","        optim.step()\n","        steps += 1\n","\n","        if steps % 100 == 0:\n","            print (f'(train_model) Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\n","\n","        total_epoch_loss += loss.item()\n","        total_epoch_acc += acc.item()\n","\n","    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n","\n","def eval_model(model, val_iter):\n","    total_epoch_loss = 0\n","    total_epoch_acc = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for idx, batch in enumerate(val_iter):\n","            # text = batch.text[0]\n","            text = batch[0]\n","            if (text.size()[0] is not batch_size):\n","                continue\n","\n","            # target = batch.label\n","            target = batch[1]\n","            target = torch.autograd.Variable(target).long()\n","            if torch.cuda.is_available():\n","                text = text.cuda()\n","                target = target.cuda()\n","            prediction = model(text)\n","            loss = loss_fn(prediction, target)\n","            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n","            acc = 100.0 * num_corrects/batch_size\n","            total_epoch_loss += loss.item()\n","            total_epoch_acc += acc.item()\n","\n","    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1VicW7ph9IaU"},"source":["## Train on SUBJ dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Oqgy0DBJ9Kvg","colab":{}},"source":["# Parameters\n","params = {'batch_size': batch_size,\n","          'shuffle': False,\n","          'drop_last': True}\n","\n","training_loader = DataLoader(Intents(cbert_train), **params)\n","testing_loader = DataLoader(Intents(cbert_test), **params)\n","val_loader = DataLoader(Intents(cbert_val), **params)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TKXTUnuCCUba","colab":{}},"source":["model = LSTMClassifierRoberta(batch_size, output_size, hidden_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LOeq7qnj9WO7","outputId":"f599e1b7-a7f3-43f7-f062-b01e9ab82a14","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["train_acc_history = []\n","val_acc_history = []\n","for epoch in range(150):\n","    train_loss, train_acc = train_model(model, training_loader, epoch)\n","    val_loss, val_acc = eval_model(model, val_loader)\n","    train_acc_history.append(train_acc)\n","    val_acc_history.append(val_acc)\n","\n","    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n","\n","print(f'Best train acc: {max(train_acc_history):.2f}%, best val acc: {max(val_acc_history):.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(train_model) Epoch: 1, Idx: 100, Training Loss: 0.6819, Training Accuracy:  62.50%\n","(train_model) Epoch: 1, Idx: 200, Training Loss: 0.7083, Training Accuracy:  43.75%\n","(train_model) Epoch: 1, Idx: 300, Training Loss: 0.6917, Training Accuracy:  50.00%\n","(train_model) Epoch: 1, Idx: 400, Training Loss: 0.7132, Training Accuracy:  43.75%\n","Epoch: 01, Train Loss: 0.694, Train Acc: 51.68%, Val. Loss: 0.690574, Val. Acc: 51.92%\n","(train_model) Epoch: 2, Idx: 100, Training Loss: 0.6702, Training Accuracy:  62.50%\n","(train_model) Epoch: 2, Idx: 200, Training Loss: 0.7244, Training Accuracy:  43.75%\n","(train_model) Epoch: 2, Idx: 300, Training Loss: 0.6912, Training Accuracy:  50.00%\n","(train_model) Epoch: 2, Idx: 400, Training Loss: 0.7339, Training Accuracy:  43.75%\n","Epoch: 02, Train Loss: 0.688, Train Acc: 53.13%, Val. Loss: 0.685759, Val. Acc: 52.56%\n","(train_model) Epoch: 3, Idx: 100, Training Loss: 0.6704, Training Accuracy:  50.00%\n","(train_model) Epoch: 3, Idx: 200, Training Loss: 0.7030, Training Accuracy:  43.75%\n","(train_model) Epoch: 3, Idx: 300, Training Loss: 0.6961, Training Accuracy:  43.75%\n","(train_model) Epoch: 3, Idx: 400, Training Loss: 0.7261, Training Accuracy:  43.75%\n","Epoch: 03, Train Loss: 0.688, Train Acc: 53.12%, Val. Loss: 0.684979, Val. Acc: 52.64%\n","(train_model) Epoch: 4, Idx: 100, Training Loss: 0.6715, Training Accuracy:  56.25%\n","(train_model) Epoch: 4, Idx: 200, Training Loss: 0.6933, Training Accuracy:  50.00%\n","(train_model) Epoch: 4, Idx: 300, Training Loss: 0.7172, Training Accuracy:  50.00%\n","(train_model) Epoch: 4, Idx: 400, Training Loss: 0.7185, Training Accuracy:  43.75%\n","Epoch: 04, Train Loss: 0.684, Train Acc: 53.68%, Val. Loss: 0.680481, Val. Acc: 53.30%\n","(train_model) Epoch: 5, Idx: 100, Training Loss: 0.6689, Training Accuracy:  62.50%\n","(train_model) Epoch: 5, Idx: 200, Training Loss: 0.6996, Training Accuracy:  50.00%\n","(train_model) Epoch: 5, Idx: 300, Training Loss: 0.7541, Training Accuracy:  43.75%\n","(train_model) Epoch: 5, Idx: 400, Training Loss: 0.7336, Training Accuracy:  43.75%\n","Epoch: 05, Train Loss: 0.682, Train Acc: 54.38%, Val. Loss: 0.676864, Val. Acc: 56.42%\n","(train_model) Epoch: 6, Idx: 100, Training Loss: 0.6791, Training Accuracy:  56.25%\n","(train_model) Epoch: 6, Idx: 200, Training Loss: 0.6920, Training Accuracy:  56.25%\n","(train_model) Epoch: 6, Idx: 300, Training Loss: 0.6928, Training Accuracy:  43.75%\n","(train_model) Epoch: 6, Idx: 400, Training Loss: 0.7267, Training Accuracy:  43.75%\n","Epoch: 06, Train Loss: 0.675, Train Acc: 55.88%, Val. Loss: 0.657795, Val. Acc: 63.32%\n","(train_model) Epoch: 7, Idx: 100, Training Loss: 0.5431, Training Accuracy:  75.00%\n","(train_model) Epoch: 7, Idx: 200, Training Loss: 0.7003, Training Accuracy:  50.00%\n","(train_model) Epoch: 7, Idx: 300, Training Loss: 0.8012, Training Accuracy:  43.75%\n","(train_model) Epoch: 7, Idx: 400, Training Loss: 0.7549, Training Accuracy:  50.00%\n","Epoch: 07, Train Loss: 0.651, Train Acc: 60.59%, Val. Loss: 0.644870, Val. Acc: 54.84%\n","(train_model) Epoch: 8, Idx: 100, Training Loss: 0.5291, Training Accuracy:  68.75%\n","(train_model) Epoch: 8, Idx: 200, Training Loss: 0.5866, Training Accuracy:  75.00%\n","(train_model) Epoch: 8, Idx: 300, Training Loss: 0.7923, Training Accuracy:  43.75%\n","(train_model) Epoch: 8, Idx: 400, Training Loss: 0.5569, Training Accuracy:  68.75%\n","Epoch: 08, Train Loss: 0.632, Train Acc: 64.51%, Val. Loss: 0.564896, Val. Acc: 71.26%\n","(train_model) Epoch: 9, Idx: 100, Training Loss: 0.6786, Training Accuracy:  56.25%\n","(train_model) Epoch: 9, Idx: 200, Training Loss: 0.5066, Training Accuracy:  81.25%\n","(train_model) Epoch: 9, Idx: 300, Training Loss: 0.5402, Training Accuracy:  75.00%\n","(train_model) Epoch: 9, Idx: 400, Training Loss: 0.7497, Training Accuracy:  62.50%\n","Epoch: 09, Train Loss: 0.580, Train Acc: 70.87%, Val. Loss: 0.504539, Val. Acc: 76.82%\n","(train_model) Epoch: 10, Idx: 100, Training Loss: 0.5885, Training Accuracy:  62.50%\n","(train_model) Epoch: 10, Idx: 200, Training Loss: 0.4583, Training Accuracy:  75.00%\n","(train_model) Epoch: 10, Idx: 300, Training Loss: 0.4954, Training Accuracy:  87.50%\n","(train_model) Epoch: 10, Idx: 400, Training Loss: 0.5700, Training Accuracy:  68.75%\n","Epoch: 10, Train Loss: 0.494, Train Acc: 76.48%, Val. Loss: 0.520184, Val. Acc: 78.14%\n","(train_model) Epoch: 11, Idx: 100, Training Loss: 0.7206, Training Accuracy:  68.75%\n","(train_model) Epoch: 11, Idx: 200, Training Loss: 0.5176, Training Accuracy:  75.00%\n","(train_model) Epoch: 11, Idx: 300, Training Loss: 0.4410, Training Accuracy:  87.50%\n","(train_model) Epoch: 11, Idx: 400, Training Loss: 0.6512, Training Accuracy:  75.00%\n","Epoch: 11, Train Loss: 0.447, Train Acc: 79.64%, Val. Loss: 0.417728, Val. Acc: 82.32%\n","(train_model) Epoch: 12, Idx: 100, Training Loss: 0.5341, Training Accuracy:  75.00%\n","(train_model) Epoch: 12, Idx: 200, Training Loss: 0.4267, Training Accuracy:  87.50%\n","(train_model) Epoch: 12, Idx: 300, Training Loss: 0.3467, Training Accuracy:  87.50%\n","(train_model) Epoch: 12, Idx: 400, Training Loss: 0.8808, Training Accuracy:  56.25%\n","Epoch: 12, Train Loss: 0.420, Train Acc: 81.21%, Val. Loss: 0.716861, Val. Acc: 72.78%\n","(train_model) Epoch: 13, Idx: 100, Training Loss: 0.7685, Training Accuracy:  68.75%\n","(train_model) Epoch: 13, Idx: 200, Training Loss: 0.6168, Training Accuracy:  75.00%\n","(train_model) Epoch: 13, Idx: 300, Training Loss: 0.4015, Training Accuracy:  87.50%\n","(train_model) Epoch: 13, Idx: 400, Training Loss: 0.7933, Training Accuracy:  56.25%\n","Epoch: 13, Train Loss: 0.384, Train Acc: 83.16%, Val. Loss: 0.445002, Val. Acc: 82.46%\n","(train_model) Epoch: 14, Idx: 100, Training Loss: 0.4162, Training Accuracy:  87.50%\n","(train_model) Epoch: 14, Idx: 200, Training Loss: 0.4404, Training Accuracy:  81.25%\n","(train_model) Epoch: 14, Idx: 300, Training Loss: 0.4073, Training Accuracy:  75.00%\n","(train_model) Epoch: 14, Idx: 400, Training Loss: 0.5444, Training Accuracy:  75.00%\n","Epoch: 14, Train Loss: 0.369, Train Acc: 84.46%, Val. Loss: 0.366371, Val. Acc: 84.26%\n","(train_model) Epoch: 15, Idx: 100, Training Loss: 0.6257, Training Accuracy:  75.00%\n","(train_model) Epoch: 15, Idx: 200, Training Loss: 0.3980, Training Accuracy:  87.50%\n","(train_model) Epoch: 15, Idx: 300, Training Loss: 0.6031, Training Accuracy:  75.00%\n","(train_model) Epoch: 15, Idx: 400, Training Loss: 0.8818, Training Accuracy:  62.50%\n","Epoch: 15, Train Loss: 0.349, Train Acc: 85.62%, Val. Loss: 0.414047, Val. Acc: 83.60%\n","(train_model) Epoch: 16, Idx: 100, Training Loss: 0.4827, Training Accuracy:  81.25%\n","(train_model) Epoch: 16, Idx: 200, Training Loss: 0.3503, Training Accuracy:  87.50%\n","(train_model) Epoch: 16, Idx: 300, Training Loss: 0.5182, Training Accuracy:  75.00%\n","(train_model) Epoch: 16, Idx: 400, Training Loss: 0.8723, Training Accuracy:  62.50%\n","Epoch: 16, Train Loss: 0.347, Train Acc: 85.30%, Val. Loss: 0.316570, Val. Acc: 86.90%\n","(train_model) Epoch: 17, Idx: 100, Training Loss: 0.4594, Training Accuracy:  81.25%\n","(train_model) Epoch: 17, Idx: 200, Training Loss: 0.4054, Training Accuracy:  87.50%\n","(train_model) Epoch: 17, Idx: 300, Training Loss: 0.3853, Training Accuracy:  81.25%\n","(train_model) Epoch: 17, Idx: 400, Training Loss: 0.6035, Training Accuracy:  68.75%\n","Epoch: 17, Train Loss: 0.338, Train Acc: 85.95%, Val. Loss: 0.399292, Val. Acc: 83.12%\n","(train_model) Epoch: 18, Idx: 100, Training Loss: 0.6350, Training Accuracy:  81.25%\n","(train_model) Epoch: 18, Idx: 200, Training Loss: 0.5408, Training Accuracy:  81.25%\n","(train_model) Epoch: 18, Idx: 300, Training Loss: 0.4560, Training Accuracy:  87.50%\n","(train_model) Epoch: 18, Idx: 400, Training Loss: 0.5346, Training Accuracy:  62.50%\n","Epoch: 18, Train Loss: 0.319, Train Acc: 86.91%, Val. Loss: 0.300506, Val. Acc: 88.18%\n","(train_model) Epoch: 19, Idx: 100, Training Loss: 0.5329, Training Accuracy:  81.25%\n","(train_model) Epoch: 19, Idx: 200, Training Loss: 0.4819, Training Accuracy:  81.25%\n","(train_model) Epoch: 19, Idx: 300, Training Loss: 0.3101, Training Accuracy:  81.25%\n","(train_model) Epoch: 19, Idx: 400, Training Loss: 0.7618, Training Accuracy:  68.75%\n","Epoch: 19, Train Loss: 0.306, Train Acc: 87.16%, Val. Loss: 0.305652, Val. Acc: 87.26%\n","(train_model) Epoch: 20, Idx: 100, Training Loss: 0.3839, Training Accuracy:  87.50%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 20, Idx: 200, Training Loss: 0.5624, Training Accuracy:  81.25%\n","(train_model) Epoch: 20, Idx: 300, Training Loss: 0.3999, Training Accuracy:  81.25%\n","(train_model) Epoch: 20, Idx: 400, Training Loss: 0.5666, Training Accuracy:  81.25%\n","Epoch: 20, Train Loss: 0.303, Train Acc: 87.55%, Val. Loss: 0.310381, Val. Acc: 87.08%\n","(train_model) Epoch: 21, Idx: 100, Training Loss: 0.4790, Training Accuracy:  81.25%\n","(train_model) Epoch: 21, Idx: 200, Training Loss: 0.4106, Training Accuracy:  87.50%\n","(train_model) Epoch: 21, Idx: 300, Training Loss: 0.3168, Training Accuracy:  87.50%\n","(train_model) Epoch: 21, Idx: 400, Training Loss: 0.6609, Training Accuracy:  75.00%\n","Epoch: 21, Train Loss: 0.295, Train Acc: 88.27%, Val. Loss: 0.352312, Val. Acc: 85.38%\n","(train_model) Epoch: 22, Idx: 100, Training Loss: 0.7148, Training Accuracy:  75.00%\n","(train_model) Epoch: 22, Idx: 200, Training Loss: 0.4522, Training Accuracy:  87.50%\n","(train_model) Epoch: 22, Idx: 300, Training Loss: 0.3601, Training Accuracy:  87.50%\n","(train_model) Epoch: 22, Idx: 400, Training Loss: 0.5987, Training Accuracy:  62.50%\n","Epoch: 22, Train Loss: 0.289, Train Acc: 88.01%, Val. Loss: 0.350898, Val. Acc: 85.10%\n","(train_model) Epoch: 23, Idx: 100, Training Loss: 0.5250, Training Accuracy:  75.00%\n","(train_model) Epoch: 23, Idx: 200, Training Loss: 0.4124, Training Accuracy:  87.50%\n","(train_model) Epoch: 23, Idx: 300, Training Loss: 0.4101, Training Accuracy:  93.75%\n","(train_model) Epoch: 23, Idx: 400, Training Loss: 0.6206, Training Accuracy:  75.00%\n","Epoch: 23, Train Loss: 0.283, Train Acc: 88.39%, Val. Loss: 0.295128, Val. Acc: 88.26%\n","(train_model) Epoch: 24, Idx: 100, Training Loss: 0.5379, Training Accuracy:  75.00%\n","(train_model) Epoch: 24, Idx: 200, Training Loss: 0.2780, Training Accuracy:  93.75%\n","(train_model) Epoch: 24, Idx: 300, Training Loss: 0.3553, Training Accuracy:  87.50%\n","(train_model) Epoch: 24, Idx: 400, Training Loss: 0.4801, Training Accuracy:  62.50%\n","Epoch: 24, Train Loss: 0.272, Train Acc: 88.83%, Val. Loss: 0.304202, Val. Acc: 88.18%\n","(train_model) Epoch: 25, Idx: 100, Training Loss: 0.4414, Training Accuracy:  75.00%\n","(train_model) Epoch: 25, Idx: 200, Training Loss: 0.5285, Training Accuracy:  81.25%\n","(train_model) Epoch: 25, Idx: 300, Training Loss: 0.3115, Training Accuracy:  87.50%\n","(train_model) Epoch: 25, Idx: 400, Training Loss: 0.5469, Training Accuracy:  75.00%\n","Epoch: 25, Train Loss: 0.271, Train Acc: 89.02%, Val. Loss: 0.293612, Val. Acc: 88.88%\n","(train_model) Epoch: 26, Idx: 100, Training Loss: 0.5276, Training Accuracy:  75.00%\n","(train_model) Epoch: 26, Idx: 200, Training Loss: 0.2410, Training Accuracy:  93.75%\n","(train_model) Epoch: 26, Idx: 300, Training Loss: 0.4508, Training Accuracy:  81.25%\n","(train_model) Epoch: 26, Idx: 400, Training Loss: 0.8683, Training Accuracy:  75.00%\n","Epoch: 26, Train Loss: 0.283, Train Acc: 89.00%, Val. Loss: 0.317744, Val. Acc: 88.22%\n","(train_model) Epoch: 27, Idx: 100, Training Loss: 0.5065, Training Accuracy:  75.00%\n","(train_model) Epoch: 27, Idx: 200, Training Loss: 0.4221, Training Accuracy:  87.50%\n","(train_model) Epoch: 27, Idx: 300, Training Loss: 0.2263, Training Accuracy:  93.75%\n","(train_model) Epoch: 27, Idx: 400, Training Loss: 0.6614, Training Accuracy:  75.00%\n","Epoch: 27, Train Loss: 0.252, Train Acc: 89.99%, Val. Loss: 0.315211, Val. Acc: 87.98%\n","(train_model) Epoch: 28, Idx: 100, Training Loss: 0.4772, Training Accuracy:  81.25%\n","(train_model) Epoch: 28, Idx: 200, Training Loss: 0.3282, Training Accuracy:  81.25%\n","(train_model) Epoch: 28, Idx: 300, Training Loss: 0.3162, Training Accuracy:  87.50%\n","(train_model) Epoch: 28, Idx: 400, Training Loss: 0.4587, Training Accuracy:  81.25%\n","Epoch: 28, Train Loss: 0.246, Train Acc: 90.14%, Val. Loss: 0.343096, Val. Acc: 87.56%\n","(train_model) Epoch: 29, Idx: 100, Training Loss: 0.4583, Training Accuracy:  75.00%\n","(train_model) Epoch: 29, Idx: 200, Training Loss: 0.5501, Training Accuracy:  81.25%\n","(train_model) Epoch: 29, Idx: 300, Training Loss: 0.3721, Training Accuracy:  81.25%\n","(train_model) Epoch: 29, Idx: 400, Training Loss: 0.4901, Training Accuracy:  68.75%\n","Epoch: 29, Train Loss: 0.246, Train Acc: 89.99%, Val. Loss: 0.302961, Val. Acc: 88.92%\n","(train_model) Epoch: 30, Idx: 100, Training Loss: 0.4949, Training Accuracy:  68.75%\n","(train_model) Epoch: 30, Idx: 200, Training Loss: 0.4329, Training Accuracy:  81.25%\n","(train_model) Epoch: 30, Idx: 300, Training Loss: 0.2404, Training Accuracy:  87.50%\n","(train_model) Epoch: 30, Idx: 400, Training Loss: 0.5839, Training Accuracy:  87.50%\n","Epoch: 30, Train Loss: 0.238, Train Acc: 90.92%, Val. Loss: 0.303276, Val. Acc: 88.66%\n","(train_model) Epoch: 31, Idx: 100, Training Loss: 0.2659, Training Accuracy:  87.50%\n","(train_model) Epoch: 31, Idx: 200, Training Loss: 0.3666, Training Accuracy:  87.50%\n","(train_model) Epoch: 31, Idx: 300, Training Loss: 0.1936, Training Accuracy:  87.50%\n","(train_model) Epoch: 31, Idx: 400, Training Loss: 0.4104, Training Accuracy:  93.75%\n","Epoch: 31, Train Loss: 0.229, Train Acc: 90.82%, Val. Loss: 0.289461, Val. Acc: 88.96%\n","(train_model) Epoch: 32, Idx: 100, Training Loss: 0.2845, Training Accuracy:  87.50%\n","(train_model) Epoch: 32, Idx: 200, Training Loss: 0.4707, Training Accuracy:  81.25%\n","(train_model) Epoch: 32, Idx: 300, Training Loss: 0.3898, Training Accuracy:  81.25%\n","(train_model) Epoch: 32, Idx: 400, Training Loss: 0.4857, Training Accuracy:  75.00%\n","Epoch: 32, Train Loss: 0.224, Train Acc: 91.25%, Val. Loss: 0.322522, Val. Acc: 87.64%\n","(train_model) Epoch: 33, Idx: 100, Training Loss: 0.3708, Training Accuracy:  75.00%\n","(train_model) Epoch: 33, Idx: 200, Training Loss: 0.4409, Training Accuracy:  81.25%\n","(train_model) Epoch: 33, Idx: 300, Training Loss: 0.1188, Training Accuracy:  100.00%\n","(train_model) Epoch: 33, Idx: 400, Training Loss: 0.4404, Training Accuracy:  81.25%\n","Epoch: 33, Train Loss: 0.219, Train Acc: 91.55%, Val. Loss: 0.488274, Val. Acc: 80.62%\n","(train_model) Epoch: 34, Idx: 100, Training Loss: 0.6826, Training Accuracy:  68.75%\n","(train_model) Epoch: 34, Idx: 200, Training Loss: 0.4088, Training Accuracy:  87.50%\n","(train_model) Epoch: 34, Idx: 300, Training Loss: 0.2174, Training Accuracy:  87.50%\n","(train_model) Epoch: 34, Idx: 400, Training Loss: 0.4563, Training Accuracy:  75.00%\n","Epoch: 34, Train Loss: 0.221, Train Acc: 91.58%, Val. Loss: 0.344594, Val. Acc: 86.38%\n","(train_model) Epoch: 35, Idx: 100, Training Loss: 0.4829, Training Accuracy:  75.00%\n","(train_model) Epoch: 35, Idx: 200, Training Loss: 0.2190, Training Accuracy:  87.50%\n","(train_model) Epoch: 35, Idx: 300, Training Loss: 0.1921, Training Accuracy:  87.50%\n","(train_model) Epoch: 35, Idx: 400, Training Loss: 0.3107, Training Accuracy:  87.50%\n","Epoch: 35, Train Loss: 0.208, Train Acc: 91.85%, Val. Loss: 0.379370, Val. Acc: 86.26%\n","(train_model) Epoch: 36, Idx: 100, Training Loss: 0.0757, Training Accuracy:  100.00%\n","(train_model) Epoch: 36, Idx: 200, Training Loss: 0.1722, Training Accuracy:  93.75%\n","(train_model) Epoch: 36, Idx: 300, Training Loss: 0.1884, Training Accuracy:  93.75%\n","(train_model) Epoch: 36, Idx: 400, Training Loss: 0.4234, Training Accuracy:  81.25%\n","Epoch: 36, Train Loss: 0.210, Train Acc: 92.24%, Val. Loss: 0.412226, Val. Acc: 85.14%\n","(train_model) Epoch: 37, Idx: 100, Training Loss: 0.4443, Training Accuracy:  87.50%\n","(train_model) Epoch: 37, Idx: 200, Training Loss: 0.2148, Training Accuracy:  93.75%\n","(train_model) Epoch: 37, Idx: 300, Training Loss: 0.1455, Training Accuracy:  93.75%\n","(train_model) Epoch: 37, Idx: 400, Training Loss: 0.5429, Training Accuracy:  75.00%\n","Epoch: 37, Train Loss: 0.206, Train Acc: 92.45%, Val. Loss: 0.329415, Val. Acc: 90.08%\n","(train_model) Epoch: 38, Idx: 100, Training Loss: 0.4073, Training Accuracy:  87.50%\n","(train_model) Epoch: 38, Idx: 200, Training Loss: 0.3346, Training Accuracy:  87.50%\n","(train_model) Epoch: 38, Idx: 300, Training Loss: 0.2137, Training Accuracy:  87.50%\n","(train_model) Epoch: 38, Idx: 400, Training Loss: 0.3684, Training Accuracy:  75.00%\n","Epoch: 38, Train Loss: 0.201, Train Acc: 92.35%, Val. Loss: 0.347236, Val. Acc: 87.54%\n","(train_model) Epoch: 39, Idx: 100, Training Loss: 0.3733, Training Accuracy:  68.75%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 39, Idx: 200, Training Loss: 0.1947, Training Accuracy:  93.75%\n","(train_model) Epoch: 39, Idx: 300, Training Loss: 0.0871, Training Accuracy:  100.00%\n","(train_model) Epoch: 39, Idx: 400, Training Loss: 0.2299, Training Accuracy:  93.75%\n","Epoch: 39, Train Loss: 0.185, Train Acc: 92.84%, Val. Loss: 0.540421, Val. Acc: 80.06%\n","(train_model) Epoch: 40, Idx: 100, Training Loss: 0.2993, Training Accuracy:  93.75%\n","(train_model) Epoch: 40, Idx: 200, Training Loss: 0.1726, Training Accuracy:  93.75%\n","(train_model) Epoch: 40, Idx: 300, Training Loss: 0.0302, Training Accuracy:  100.00%\n","(train_model) Epoch: 40, Idx: 400, Training Loss: 0.3651, Training Accuracy:  81.25%\n","Epoch: 40, Train Loss: 0.192, Train Acc: 92.58%, Val. Loss: 0.459017, Val. Acc: 83.56%\n","(train_model) Epoch: 41, Idx: 100, Training Loss: 0.1701, Training Accuracy:  93.75%\n","(train_model) Epoch: 41, Idx: 200, Training Loss: 0.1406, Training Accuracy:  93.75%\n","(train_model) Epoch: 41, Idx: 300, Training Loss: 0.1278, Training Accuracy:  93.75%\n","(train_model) Epoch: 41, Idx: 400, Training Loss: 0.7031, Training Accuracy:  68.75%\n","Epoch: 41, Train Loss: 0.179, Train Acc: 93.15%, Val. Loss: 0.471447, Val. Acc: 84.18%\n","(train_model) Epoch: 42, Idx: 100, Training Loss: 0.2023, Training Accuracy:  93.75%\n","(train_model) Epoch: 42, Idx: 200, Training Loss: 0.2885, Training Accuracy:  93.75%\n","(train_model) Epoch: 42, Idx: 300, Training Loss: 0.1768, Training Accuracy:  87.50%\n","(train_model) Epoch: 42, Idx: 400, Training Loss: 0.4879, Training Accuracy:  87.50%\n","Epoch: 42, Train Loss: 0.179, Train Acc: 93.19%, Val. Loss: 0.554786, Val. Acc: 82.80%\n","(train_model) Epoch: 43, Idx: 100, Training Loss: 0.0802, Training Accuracy:  100.00%\n","(train_model) Epoch: 43, Idx: 200, Training Loss: 0.2967, Training Accuracy:  93.75%\n","(train_model) Epoch: 43, Idx: 300, Training Loss: 0.1401, Training Accuracy:  93.75%\n","(train_model) Epoch: 43, Idx: 400, Training Loss: 0.4083, Training Accuracy:  81.25%\n","Epoch: 43, Train Loss: 0.176, Train Acc: 93.19%, Val. Loss: 0.453794, Val. Acc: 85.50%\n","(train_model) Epoch: 44, Idx: 100, Training Loss: 0.1698, Training Accuracy:  87.50%\n","(train_model) Epoch: 44, Idx: 200, Training Loss: 0.2857, Training Accuracy:  93.75%\n","(train_model) Epoch: 44, Idx: 300, Training Loss: 0.0849, Training Accuracy:  100.00%\n","(train_model) Epoch: 44, Idx: 400, Training Loss: 0.0519, Training Accuracy:  100.00%\n","Epoch: 44, Train Loss: 0.169, Train Acc: 93.39%, Val. Loss: 0.433067, Val. Acc: 83.04%\n","(train_model) Epoch: 45, Idx: 100, Training Loss: 0.2679, Training Accuracy:  93.75%\n","(train_model) Epoch: 45, Idx: 200, Training Loss: 0.5177, Training Accuracy:  87.50%\n","(train_model) Epoch: 45, Idx: 300, Training Loss: 0.0911, Training Accuracy:  93.75%\n","(train_model) Epoch: 45, Idx: 400, Training Loss: 0.2201, Training Accuracy:  87.50%\n","Epoch: 45, Train Loss: 0.178, Train Acc: 93.31%, Val. Loss: 0.598082, Val. Acc: 80.78%\n","(train_model) Epoch: 46, Idx: 100, Training Loss: 0.1881, Training Accuracy:  93.75%\n","(train_model) Epoch: 46, Idx: 200, Training Loss: 0.1780, Training Accuracy:  93.75%\n","(train_model) Epoch: 46, Idx: 300, Training Loss: 0.0238, Training Accuracy:  100.00%\n","(train_model) Epoch: 46, Idx: 400, Training Loss: 0.2156, Training Accuracy:  87.50%\n","Epoch: 46, Train Loss: 0.157, Train Acc: 93.91%, Val. Loss: 0.659246, Val. Acc: 77.64%\n","(train_model) Epoch: 47, Idx: 100, Training Loss: 0.2045, Training Accuracy:  93.75%\n","(train_model) Epoch: 47, Idx: 200, Training Loss: 0.0580, Training Accuracy:  100.00%\n","(train_model) Epoch: 47, Idx: 300, Training Loss: 0.0478, Training Accuracy:  100.00%\n","(train_model) Epoch: 47, Idx: 400, Training Loss: 0.2145, Training Accuracy:  87.50%\n","Epoch: 47, Train Loss: 0.155, Train Acc: 94.23%, Val. Loss: 0.562019, Val. Acc: 77.20%\n","(train_model) Epoch: 48, Idx: 100, Training Loss: 0.1219, Training Accuracy:  93.75%\n","(train_model) Epoch: 48, Idx: 200, Training Loss: 0.1190, Training Accuracy:  93.75%\n","(train_model) Epoch: 48, Idx: 300, Training Loss: 0.1000, Training Accuracy:  93.75%\n","(train_model) Epoch: 48, Idx: 400, Training Loss: 0.3526, Training Accuracy:  87.50%\n","Epoch: 48, Train Loss: 0.150, Train Acc: 94.40%, Val. Loss: 0.776016, Val. Acc: 74.48%\n","(train_model) Epoch: 49, Idx: 100, Training Loss: 0.2916, Training Accuracy:  87.50%\n","(train_model) Epoch: 49, Idx: 200, Training Loss: 0.1419, Training Accuracy:  93.75%\n","(train_model) Epoch: 49, Idx: 300, Training Loss: 0.0940, Training Accuracy:  100.00%\n","(train_model) Epoch: 49, Idx: 400, Training Loss: 0.4901, Training Accuracy:  81.25%\n","Epoch: 49, Train Loss: 0.156, Train Acc: 94.27%, Val. Loss: 0.590725, Val. Acc: 78.64%\n","(train_model) Epoch: 50, Idx: 100, Training Loss: 0.0314, Training Accuracy:  100.00%\n","(train_model) Epoch: 50, Idx: 200, Training Loss: 0.1675, Training Accuracy:  93.75%\n","(train_model) Epoch: 50, Idx: 300, Training Loss: 0.0779, Training Accuracy:  100.00%\n","(train_model) Epoch: 50, Idx: 400, Training Loss: 0.3918, Training Accuracy:  87.50%\n","Epoch: 50, Train Loss: 0.138, Train Acc: 94.82%, Val. Loss: 0.666934, Val. Acc: 76.84%\n","(train_model) Epoch: 51, Idx: 100, Training Loss: 0.0674, Training Accuracy:  100.00%\n","(train_model) Epoch: 51, Idx: 200, Training Loss: 0.0291, Training Accuracy:  100.00%\n","(train_model) Epoch: 51, Idx: 300, Training Loss: 0.1808, Training Accuracy:  93.75%\n","(train_model) Epoch: 51, Idx: 400, Training Loss: 0.4973, Training Accuracy:  75.00%\n","Epoch: 51, Train Loss: 0.140, Train Acc: 94.59%, Val. Loss: 0.655338, Val. Acc: 76.14%\n","(train_model) Epoch: 52, Idx: 100, Training Loss: 0.2917, Training Accuracy:  87.50%\n","(train_model) Epoch: 52, Idx: 200, Training Loss: 0.1130, Training Accuracy:  93.75%\n","(train_model) Epoch: 52, Idx: 300, Training Loss: 0.0192, Training Accuracy:  100.00%\n","(train_model) Epoch: 52, Idx: 400, Training Loss: 0.0988, Training Accuracy:  93.75%\n","Epoch: 52, Train Loss: 0.138, Train Acc: 94.93%, Val. Loss: 0.743524, Val. Acc: 73.98%\n","(train_model) Epoch: 53, Idx: 100, Training Loss: 0.1235, Training Accuracy:  93.75%\n","(train_model) Epoch: 53, Idx: 200, Training Loss: 0.0341, Training Accuracy:  100.00%\n","(train_model) Epoch: 53, Idx: 300, Training Loss: 0.1364, Training Accuracy:  93.75%\n","(train_model) Epoch: 53, Idx: 400, Training Loss: 0.1873, Training Accuracy:  93.75%\n","Epoch: 53, Train Loss: 0.131, Train Acc: 95.22%, Val. Loss: 0.568051, Val. Acc: 79.28%\n","(train_model) Epoch: 54, Idx: 100, Training Loss: 0.0161, Training Accuracy:  100.00%\n","(train_model) Epoch: 54, Idx: 200, Training Loss: 0.0592, Training Accuracy:  100.00%\n","(train_model) Epoch: 54, Idx: 300, Training Loss: 0.0636, Training Accuracy:  100.00%\n","(train_model) Epoch: 54, Idx: 400, Training Loss: 0.1572, Training Accuracy:  93.75%\n","Epoch: 54, Train Loss: 0.131, Train Acc: 95.03%, Val. Loss: 0.617797, Val. Acc: 78.08%\n","(train_model) Epoch: 55, Idx: 100, Training Loss: 0.2730, Training Accuracy:  93.75%\n","(train_model) Epoch: 55, Idx: 200, Training Loss: 0.0953, Training Accuracy:  93.75%\n","(train_model) Epoch: 55, Idx: 300, Training Loss: 0.0463, Training Accuracy:  100.00%\n","(train_model) Epoch: 55, Idx: 400, Training Loss: 0.0984, Training Accuracy:  100.00%\n","Epoch: 55, Train Loss: 0.117, Train Acc: 95.58%, Val. Loss: 0.731297, Val. Acc: 76.10%\n","(train_model) Epoch: 56, Idx: 100, Training Loss: 0.1578, Training Accuracy:  93.75%\n","(train_model) Epoch: 56, Idx: 200, Training Loss: 0.0358, Training Accuracy:  100.00%\n","(train_model) Epoch: 56, Idx: 300, Training Loss: 0.0408, Training Accuracy:  100.00%\n","(train_model) Epoch: 56, Idx: 400, Training Loss: 0.1070, Training Accuracy:  93.75%\n","Epoch: 56, Train Loss: 0.124, Train Acc: 95.59%, Val. Loss: 0.778902, Val. Acc: 76.84%\n","(train_model) Epoch: 57, Idx: 100, Training Loss: 0.1098, Training Accuracy:  93.75%\n","(train_model) Epoch: 57, Idx: 200, Training Loss: 0.3140, Training Accuracy:  93.75%\n","(train_model) Epoch: 57, Idx: 300, Training Loss: 0.0731, Training Accuracy:  100.00%\n","(train_model) Epoch: 57, Idx: 400, Training Loss: 0.1473, Training Accuracy:  93.75%\n","Epoch: 57, Train Loss: 0.119, Train Acc: 95.55%, Val. Loss: 1.036474, Val. Acc: 69.00%\n","(train_model) Epoch: 58, Idx: 100, Training Loss: 0.0374, Training Accuracy:  100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 58, Idx: 200, Training Loss: 0.0173, Training Accuracy:  100.00%\n","(train_model) Epoch: 58, Idx: 300, Training Loss: 0.0363, Training Accuracy:  100.00%\n","(train_model) Epoch: 58, Idx: 400, Training Loss: 0.2328, Training Accuracy:  93.75%\n","Epoch: 58, Train Loss: 0.123, Train Acc: 95.74%, Val. Loss: 0.968990, Val. Acc: 70.62%\n","(train_model) Epoch: 59, Idx: 100, Training Loss: 0.1235, Training Accuracy:  93.75%\n","(train_model) Epoch: 59, Idx: 200, Training Loss: 0.3846, Training Accuracy:  87.50%\n","(train_model) Epoch: 59, Idx: 300, Training Loss: 0.1693, Training Accuracy:  93.75%\n","(train_model) Epoch: 59, Idx: 400, Training Loss: 0.1271, Training Accuracy:  93.75%\n","Epoch: 59, Train Loss: 0.123, Train Acc: 95.59%, Val. Loss: 0.668028, Val. Acc: 79.32%\n","(train_model) Epoch: 60, Idx: 100, Training Loss: 0.0789, Training Accuracy:  100.00%\n","(train_model) Epoch: 60, Idx: 200, Training Loss: 0.0880, Training Accuracy:  93.75%\n","(train_model) Epoch: 60, Idx: 300, Training Loss: 0.0492, Training Accuracy:  100.00%\n","(train_model) Epoch: 60, Idx: 400, Training Loss: 0.2174, Training Accuracy:  87.50%\n","Epoch: 60, Train Loss: 0.113, Train Acc: 95.92%, Val. Loss: 0.809770, Val. Acc: 74.00%\n","(train_model) Epoch: 61, Idx: 100, Training Loss: 0.0724, Training Accuracy:  100.00%\n","(train_model) Epoch: 61, Idx: 200, Training Loss: 0.0258, Training Accuracy:  100.00%\n","(train_model) Epoch: 61, Idx: 300, Training Loss: 0.0447, Training Accuracy:  100.00%\n","(train_model) Epoch: 61, Idx: 400, Training Loss: 0.1029, Training Accuracy:  93.75%\n","Epoch: 61, Train Loss: 0.105, Train Acc: 96.22%, Val. Loss: 0.689845, Val. Acc: 76.50%\n","(train_model) Epoch: 62, Idx: 100, Training Loss: 0.0187, Training Accuracy:  100.00%\n","(train_model) Epoch: 62, Idx: 200, Training Loss: 0.2223, Training Accuracy:  93.75%\n","(train_model) Epoch: 62, Idx: 300, Training Loss: 0.1058, Training Accuracy:  93.75%\n","(train_model) Epoch: 62, Idx: 400, Training Loss: 0.2520, Training Accuracy:  87.50%\n","Epoch: 62, Train Loss: 0.104, Train Acc: 96.20%, Val. Loss: 0.681128, Val. Acc: 76.84%\n","(train_model) Epoch: 63, Idx: 100, Training Loss: 0.0300, Training Accuracy:  100.00%\n","(train_model) Epoch: 63, Idx: 200, Training Loss: 0.0487, Training Accuracy:  100.00%\n","(train_model) Epoch: 63, Idx: 300, Training Loss: 0.0454, Training Accuracy:  100.00%\n","(train_model) Epoch: 63, Idx: 400, Training Loss: 0.1509, Training Accuracy:  93.75%\n","Epoch: 63, Train Loss: 0.099, Train Acc: 96.29%, Val. Loss: 0.673403, Val. Acc: 75.36%\n","(train_model) Epoch: 64, Idx: 100, Training Loss: 0.0150, Training Accuracy:  100.00%\n","(train_model) Epoch: 64, Idx: 200, Training Loss: 0.0696, Training Accuracy:  93.75%\n","(train_model) Epoch: 64, Idx: 300, Training Loss: 0.1257, Training Accuracy:  93.75%\n","(train_model) Epoch: 64, Idx: 400, Training Loss: 0.1121, Training Accuracy:  93.75%\n","Epoch: 64, Train Loss: 0.096, Train Acc: 96.57%, Val. Loss: 0.727754, Val. Acc: 73.98%\n","(train_model) Epoch: 65, Idx: 100, Training Loss: 0.0193, Training Accuracy:  100.00%\n","(train_model) Epoch: 65, Idx: 200, Training Loss: 0.0023, Training Accuracy:  100.00%\n","(train_model) Epoch: 65, Idx: 300, Training Loss: 0.1163, Training Accuracy:  93.75%\n","(train_model) Epoch: 65, Idx: 400, Training Loss: 0.0267, Training Accuracy:  100.00%\n","Epoch: 65, Train Loss: 0.111, Train Acc: 96.15%, Val. Loss: 0.684816, Val. Acc: 74.04%\n","(train_model) Epoch: 66, Idx: 100, Training Loss: 0.1543, Training Accuracy:  93.75%\n","(train_model) Epoch: 66, Idx: 200, Training Loss: 0.2351, Training Accuracy:  81.25%\n","(train_model) Epoch: 66, Idx: 300, Training Loss: 0.1243, Training Accuracy:  93.75%\n","(train_model) Epoch: 66, Idx: 400, Training Loss: 0.3513, Training Accuracy:  87.50%\n","Epoch: 66, Train Loss: 0.142, Train Acc: 95.40%, Val. Loss: 0.480358, Val. Acc: 81.00%\n","(train_model) Epoch: 67, Idx: 100, Training Loss: 0.3433, Training Accuracy:  87.50%\n","(train_model) Epoch: 67, Idx: 200, Training Loss: 0.2958, Training Accuracy:  87.50%\n","(train_model) Epoch: 67, Idx: 300, Training Loss: 0.0443, Training Accuracy:  100.00%\n","(train_model) Epoch: 67, Idx: 400, Training Loss: 0.3231, Training Accuracy:  93.75%\n","Epoch: 67, Train Loss: 0.153, Train Acc: 95.41%, Val. Loss: 0.436016, Val. Acc: 83.46%\n","(train_model) Epoch: 68, Idx: 100, Training Loss: 0.1949, Training Accuracy:  87.50%\n","(train_model) Epoch: 68, Idx: 200, Training Loss: 0.1683, Training Accuracy:  93.75%\n","(train_model) Epoch: 68, Idx: 300, Training Loss: 0.1195, Training Accuracy:  87.50%\n","(train_model) Epoch: 68, Idx: 400, Training Loss: 0.2646, Training Accuracy:  87.50%\n","Epoch: 68, Train Loss: 0.109, Train Acc: 96.25%, Val. Loss: 0.519559, Val. Acc: 79.34%\n","(train_model) Epoch: 69, Idx: 100, Training Loss: 0.0114, Training Accuracy:  100.00%\n","(train_model) Epoch: 69, Idx: 200, Training Loss: 0.0441, Training Accuracy:  100.00%\n","(train_model) Epoch: 69, Idx: 300, Training Loss: 0.4126, Training Accuracy:  87.50%\n","(train_model) Epoch: 69, Idx: 400, Training Loss: 0.0937, Training Accuracy:  93.75%\n","Epoch: 69, Train Loss: 0.128, Train Acc: 95.98%, Val. Loss: 0.369485, Val. Acc: 85.22%\n","(train_model) Epoch: 70, Idx: 100, Training Loss: 0.2104, Training Accuracy:  87.50%\n","(train_model) Epoch: 70, Idx: 200, Training Loss: 0.0274, Training Accuracy:  100.00%\n","(train_model) Epoch: 70, Idx: 300, Training Loss: 0.1521, Training Accuracy:  93.75%\n","(train_model) Epoch: 70, Idx: 400, Training Loss: 0.5977, Training Accuracy:  75.00%\n","Epoch: 70, Train Loss: 0.131, Train Acc: 95.65%, Val. Loss: 0.317701, Val. Acc: 88.70%\n","(train_model) Epoch: 71, Idx: 100, Training Loss: 0.0312, Training Accuracy:  100.00%\n","(train_model) Epoch: 71, Idx: 200, Training Loss: 0.0478, Training Accuracy:  100.00%\n","(train_model) Epoch: 71, Idx: 300, Training Loss: 0.1290, Training Accuracy:  93.75%\n","(train_model) Epoch: 71, Idx: 400, Training Loss: 0.3766, Training Accuracy:  93.75%\n","Epoch: 71, Train Loss: 0.120, Train Acc: 95.76%, Val. Loss: 0.314834, Val. Acc: 88.60%\n","(train_model) Epoch: 72, Idx: 100, Training Loss: 0.1364, Training Accuracy:  93.75%\n","(train_model) Epoch: 72, Idx: 200, Training Loss: 0.0530, Training Accuracy:  100.00%\n","(train_model) Epoch: 72, Idx: 300, Training Loss: 0.1817, Training Accuracy:  93.75%\n","(train_model) Epoch: 72, Idx: 400, Training Loss: 0.2189, Training Accuracy:  93.75%\n","Epoch: 72, Train Loss: 0.123, Train Acc: 95.80%, Val. Loss: 0.332762, Val. Acc: 86.94%\n","(train_model) Epoch: 73, Idx: 100, Training Loss: 0.1018, Training Accuracy:  100.00%\n","(train_model) Epoch: 73, Idx: 200, Training Loss: 0.0821, Training Accuracy:  93.75%\n","(train_model) Epoch: 73, Idx: 300, Training Loss: 0.0193, Training Accuracy:  100.00%\n","(train_model) Epoch: 73, Idx: 400, Training Loss: 0.1065, Training Accuracy:  93.75%\n","Epoch: 73, Train Loss: 0.117, Train Acc: 95.91%, Val. Loss: 0.322342, Val. Acc: 86.58%\n","(train_model) Epoch: 74, Idx: 100, Training Loss: 0.2186, Training Accuracy:  93.75%\n","(train_model) Epoch: 74, Idx: 200, Training Loss: 0.1154, Training Accuracy:  93.75%\n","(train_model) Epoch: 74, Idx: 300, Training Loss: 0.1834, Training Accuracy:  93.75%\n","(train_model) Epoch: 74, Idx: 400, Training Loss: 0.1568, Training Accuracy:  93.75%\n","Epoch: 74, Train Loss: 0.124, Train Acc: 95.78%, Val. Loss: 0.592806, Val. Acc: 62.02%\n","(train_model) Epoch: 75, Idx: 100, Training Loss: 0.1529, Training Accuracy:  93.75%\n","(train_model) Epoch: 75, Idx: 200, Training Loss: 0.2172, Training Accuracy:  93.75%\n","(train_model) Epoch: 75, Idx: 300, Training Loss: 0.0984, Training Accuracy:  93.75%\n","(train_model) Epoch: 75, Idx: 400, Training Loss: 0.4602, Training Accuracy:  81.25%\n","Epoch: 75, Train Loss: 0.150, Train Acc: 94.81%, Val. Loss: 0.415500, Val. Acc: 84.36%\n","(train_model) Epoch: 76, Idx: 100, Training Loss: 0.0307, Training Accuracy:  100.00%\n","(train_model) Epoch: 76, Idx: 200, Training Loss: 0.1563, Training Accuracy:  93.75%\n","(train_model) Epoch: 76, Idx: 300, Training Loss: 0.0726, Training Accuracy:  100.00%\n","(train_model) Epoch: 76, Idx: 400, Training Loss: 0.2263, Training Accuracy:  87.50%\n","Epoch: 76, Train Loss: 0.136, Train Acc: 94.99%, Val. Loss: 0.269194, Val. Acc: 88.04%\n","(train_model) Epoch: 77, Idx: 100, Training Loss: 0.2076, Training Accuracy:  93.75%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 77, Idx: 200, Training Loss: 0.0197, Training Accuracy:  100.00%\n","(train_model) Epoch: 77, Idx: 300, Training Loss: 0.0829, Training Accuracy:  100.00%\n","(train_model) Epoch: 77, Idx: 400, Training Loss: 0.2610, Training Accuracy:  87.50%\n","Epoch: 77, Train Loss: 0.111, Train Acc: 96.09%, Val. Loss: 0.323962, Val. Acc: 86.70%\n","(train_model) Epoch: 78, Idx: 100, Training Loss: 0.0269, Training Accuracy:  100.00%\n","(train_model) Epoch: 78, Idx: 200, Training Loss: 0.1713, Training Accuracy:  93.75%\n","(train_model) Epoch: 78, Idx: 300, Training Loss: 0.1443, Training Accuracy:  93.75%\n","(train_model) Epoch: 78, Idx: 400, Training Loss: 0.0306, Training Accuracy:  100.00%\n","Epoch: 78, Train Loss: 0.115, Train Acc: 95.93%, Val. Loss: 0.321099, Val. Acc: 86.64%\n","(train_model) Epoch: 79, Idx: 100, Training Loss: 0.0948, Training Accuracy:  93.75%\n","(train_model) Epoch: 79, Idx: 200, Training Loss: 0.1329, Training Accuracy:  87.50%\n","(train_model) Epoch: 79, Idx: 300, Training Loss: 0.0854, Training Accuracy:  100.00%\n","(train_model) Epoch: 79, Idx: 400, Training Loss: 0.1996, Training Accuracy:  93.75%\n","Epoch: 79, Train Loss: 0.103, Train Acc: 96.48%, Val. Loss: 0.335022, Val. Acc: 84.74%\n","(train_model) Epoch: 80, Idx: 100, Training Loss: 0.0416, Training Accuracy:  100.00%\n","(train_model) Epoch: 80, Idx: 200, Training Loss: 0.3083, Training Accuracy:  93.75%\n","(train_model) Epoch: 80, Idx: 300, Training Loss: 0.1740, Training Accuracy:  93.75%\n","(train_model) Epoch: 80, Idx: 400, Training Loss: 0.0170, Training Accuracy:  100.00%\n","Epoch: 80, Train Loss: 0.105, Train Acc: 96.44%, Val. Loss: 0.335425, Val. Acc: 85.26%\n","(train_model) Epoch: 81, Idx: 100, Training Loss: 0.0629, Training Accuracy:  100.00%\n","(train_model) Epoch: 81, Idx: 200, Training Loss: 0.1366, Training Accuracy:  93.75%\n","(train_model) Epoch: 81, Idx: 300, Training Loss: 0.0271, Training Accuracy:  100.00%\n","(train_model) Epoch: 81, Idx: 400, Training Loss: 0.1452, Training Accuracy:  93.75%\n","Epoch: 81, Train Loss: 0.110, Train Acc: 96.25%, Val. Loss: 0.334093, Val. Acc: 85.70%\n","(train_model) Epoch: 82, Idx: 100, Training Loss: 0.0647, Training Accuracy:  100.00%\n","(train_model) Epoch: 82, Idx: 200, Training Loss: 0.1354, Training Accuracy:  93.75%\n","(train_model) Epoch: 82, Idx: 300, Training Loss: 0.1037, Training Accuracy:  93.75%\n","(train_model) Epoch: 82, Idx: 400, Training Loss: 0.0119, Training Accuracy:  100.00%\n","Epoch: 82, Train Loss: 0.103, Train Acc: 96.32%, Val. Loss: 0.363321, Val. Acc: 80.76%\n","(train_model) Epoch: 83, Idx: 100, Training Loss: 0.3033, Training Accuracy:  93.75%\n","(train_model) Epoch: 83, Idx: 200, Training Loss: 0.0093, Training Accuracy:  100.00%\n","(train_model) Epoch: 83, Idx: 300, Training Loss: 0.1328, Training Accuracy:  93.75%\n","(train_model) Epoch: 83, Idx: 400, Training Loss: 0.1305, Training Accuracy:  93.75%\n","Epoch: 83, Train Loss: 0.095, Train Acc: 96.73%, Val. Loss: 0.373749, Val. Acc: 82.14%\n","(train_model) Epoch: 84, Idx: 100, Training Loss: 0.0772, Training Accuracy:  93.75%\n","(train_model) Epoch: 84, Idx: 200, Training Loss: 0.3530, Training Accuracy:  93.75%\n","(train_model) Epoch: 84, Idx: 300, Training Loss: 0.0368, Training Accuracy:  100.00%\n","(train_model) Epoch: 84, Idx: 400, Training Loss: 0.0945, Training Accuracy:  100.00%\n","Epoch: 84, Train Loss: 0.082, Train Acc: 97.32%, Val. Loss: 0.358810, Val. Acc: 82.08%\n","(train_model) Epoch: 85, Idx: 100, Training Loss: 0.0544, Training Accuracy:  100.00%\n","(train_model) Epoch: 85, Idx: 200, Training Loss: 0.0140, Training Accuracy:  100.00%\n","(train_model) Epoch: 85, Idx: 300, Training Loss: 0.2975, Training Accuracy:  93.75%\n","(train_model) Epoch: 85, Idx: 400, Training Loss: 0.1357, Training Accuracy:  93.75%\n","Epoch: 85, Train Loss: 0.085, Train Acc: 97.10%, Val. Loss: 0.301036, Val. Acc: 87.08%\n","(train_model) Epoch: 86, Idx: 100, Training Loss: 0.0800, Training Accuracy:  93.75%\n","(train_model) Epoch: 86, Idx: 200, Training Loss: 0.0296, Training Accuracy:  100.00%\n","(train_model) Epoch: 86, Idx: 300, Training Loss: 0.0417, Training Accuracy:  100.00%\n","(train_model) Epoch: 86, Idx: 400, Training Loss: 0.0468, Training Accuracy:  100.00%\n","Epoch: 86, Train Loss: 0.082, Train Acc: 97.39%, Val. Loss: 0.357989, Val. Acc: 80.98%\n","(train_model) Epoch: 87, Idx: 100, Training Loss: 0.0215, Training Accuracy:  100.00%\n","(train_model) Epoch: 87, Idx: 200, Training Loss: 0.0284, Training Accuracy:  100.00%\n","(train_model) Epoch: 87, Idx: 300, Training Loss: 0.0503, Training Accuracy:  100.00%\n","(train_model) Epoch: 87, Idx: 400, Training Loss: 0.0678, Training Accuracy:  100.00%\n","Epoch: 87, Train Loss: 0.091, Train Acc: 96.94%, Val. Loss: 0.324517, Val. Acc: 83.32%\n","(train_model) Epoch: 88, Idx: 100, Training Loss: 0.0882, Training Accuracy:  100.00%\n","(train_model) Epoch: 88, Idx: 200, Training Loss: 0.0359, Training Accuracy:  100.00%\n","(train_model) Epoch: 88, Idx: 300, Training Loss: 0.0258, Training Accuracy:  100.00%\n","(train_model) Epoch: 88, Idx: 400, Training Loss: 0.0850, Training Accuracy:  93.75%\n","Epoch: 88, Train Loss: 0.078, Train Acc: 97.09%, Val. Loss: 0.362179, Val. Acc: 81.76%\n","(train_model) Epoch: 89, Idx: 100, Training Loss: 0.0206, Training Accuracy:  100.00%\n","(train_model) Epoch: 89, Idx: 200, Training Loss: 0.1058, Training Accuracy:  93.75%\n","(train_model) Epoch: 89, Idx: 300, Training Loss: 0.0802, Training Accuracy:  93.75%\n","(train_model) Epoch: 89, Idx: 400, Training Loss: 0.0566, Training Accuracy:  100.00%\n","Epoch: 89, Train Loss: 0.069, Train Acc: 97.61%, Val. Loss: 0.359945, Val. Acc: 80.82%\n","(train_model) Epoch: 90, Idx: 100, Training Loss: 0.0902, Training Accuracy:  93.75%\n","(train_model) Epoch: 90, Idx: 200, Training Loss: 0.0933, Training Accuracy:  93.75%\n","(train_model) Epoch: 90, Idx: 300, Training Loss: 0.1013, Training Accuracy:  93.75%\n","(train_model) Epoch: 90, Idx: 400, Training Loss: 0.0332, Training Accuracy:  100.00%\n","Epoch: 90, Train Loss: 0.123, Train Acc: 95.69%, Val. Loss: 0.493064, Val. Acc: 73.72%\n","(train_model) Epoch: 91, Idx: 100, Training Loss: 0.2287, Training Accuracy:  93.75%\n","(train_model) Epoch: 91, Idx: 200, Training Loss: 0.3040, Training Accuracy:  93.75%\n","(train_model) Epoch: 91, Idx: 300, Training Loss: 0.0622, Training Accuracy:  100.00%\n","(train_model) Epoch: 91, Idx: 400, Training Loss: 0.2407, Training Accuracy:  87.50%\n","Epoch: 91, Train Loss: 0.138, Train Acc: 95.43%, Val. Loss: 0.350825, Val. Acc: 81.78%\n","(train_model) Epoch: 92, Idx: 100, Training Loss: 0.4364, Training Accuracy:  87.50%\n","(train_model) Epoch: 92, Idx: 200, Training Loss: 0.0738, Training Accuracy:  100.00%\n","(train_model) Epoch: 92, Idx: 300, Training Loss: 0.0576, Training Accuracy:  100.00%\n","(train_model) Epoch: 92, Idx: 400, Training Loss: 0.4581, Training Accuracy:  87.50%\n","Epoch: 92, Train Loss: 0.135, Train Acc: 95.14%, Val. Loss: 0.414815, Val. Acc: 77.32%\n","(train_model) Epoch: 93, Idx: 100, Training Loss: 0.0106, Training Accuracy:  100.00%\n","(train_model) Epoch: 93, Idx: 200, Training Loss: 0.2753, Training Accuracy:  87.50%\n","(train_model) Epoch: 93, Idx: 300, Training Loss: 0.1818, Training Accuracy:  87.50%\n","(train_model) Epoch: 93, Idx: 400, Training Loss: 0.0952, Training Accuracy:  100.00%\n","Epoch: 93, Train Loss: 0.137, Train Acc: 94.96%, Val. Loss: 0.618536, Val. Acc: 78.20%\n","(train_model) Epoch: 94, Idx: 100, Training Loss: 0.2594, Training Accuracy:  93.75%\n","(train_model) Epoch: 94, Idx: 200, Training Loss: 0.0058, Training Accuracy:  100.00%\n","(train_model) Epoch: 94, Idx: 300, Training Loss: 0.0940, Training Accuracy:  93.75%\n","(train_model) Epoch: 94, Idx: 400, Training Loss: 0.1092, Training Accuracy:  93.75%\n","Epoch: 94, Train Loss: 0.142, Train Acc: 95.29%, Val. Loss: 0.324524, Val. Acc: 86.46%\n","(train_model) Epoch: 95, Idx: 100, Training Loss: 0.0899, Training Accuracy:  100.00%\n","(train_model) Epoch: 95, Idx: 200, Training Loss: 0.3585, Training Accuracy:  87.50%\n","(train_model) Epoch: 95, Idx: 300, Training Loss: 0.3348, Training Accuracy:  93.75%\n","(train_model) Epoch: 95, Idx: 400, Training Loss: 0.1671, Training Accuracy:  93.75%\n","Epoch: 95, Train Loss: 0.143, Train Acc: 95.19%, Val. Loss: 0.371805, Val. Acc: 83.64%\n","(train_model) Epoch: 96, Idx: 100, Training Loss: 0.2828, Training Accuracy:  93.75%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 96, Idx: 200, Training Loss: 0.0392, Training Accuracy:  100.00%\n","(train_model) Epoch: 96, Idx: 300, Training Loss: 0.1077, Training Accuracy:  93.75%\n","(train_model) Epoch: 96, Idx: 400, Training Loss: 0.3242, Training Accuracy:  93.75%\n","Epoch: 96, Train Loss: 0.119, Train Acc: 95.73%, Val. Loss: 0.447640, Val. Acc: 83.30%\n","(train_model) Epoch: 97, Idx: 100, Training Loss: 0.1039, Training Accuracy:  93.75%\n","(train_model) Epoch: 97, Idx: 200, Training Loss: 0.0730, Training Accuracy:  100.00%\n","(train_model) Epoch: 97, Idx: 300, Training Loss: 0.0071, Training Accuracy:  100.00%\n","(train_model) Epoch: 97, Idx: 400, Training Loss: 0.3449, Training Accuracy:  81.25%\n","Epoch: 97, Train Loss: 0.132, Train Acc: 95.48%, Val. Loss: 0.344482, Val. Acc: 87.90%\n","(train_model) Epoch: 98, Idx: 100, Training Loss: 0.1955, Training Accuracy:  87.50%\n","(train_model) Epoch: 98, Idx: 200, Training Loss: 0.0827, Training Accuracy:  93.75%\n","(train_model) Epoch: 98, Idx: 300, Training Loss: 0.2119, Training Accuracy:  93.75%\n","(train_model) Epoch: 98, Idx: 400, Training Loss: 0.1138, Training Accuracy:  93.75%\n","Epoch: 98, Train Loss: 0.117, Train Acc: 95.85%, Val. Loss: 0.321218, Val. Acc: 87.78%\n","(train_model) Epoch: 99, Idx: 100, Training Loss: 0.0799, Training Accuracy:  93.75%\n","(train_model) Epoch: 99, Idx: 200, Training Loss: 0.1173, Training Accuracy:  93.75%\n","(train_model) Epoch: 99, Idx: 300, Training Loss: 0.2587, Training Accuracy:  87.50%\n","(train_model) Epoch: 99, Idx: 400, Training Loss: 0.0237, Training Accuracy:  100.00%\n","Epoch: 99, Train Loss: 0.125, Train Acc: 95.65%, Val. Loss: 0.306065, Val. Acc: 85.80%\n","(train_model) Epoch: 100, Idx: 100, Training Loss: 0.0019, Training Accuracy:  100.00%\n","(train_model) Epoch: 100, Idx: 200, Training Loss: 0.0156, Training Accuracy:  100.00%\n","(train_model) Epoch: 100, Idx: 300, Training Loss: 0.1168, Training Accuracy:  93.75%\n","(train_model) Epoch: 100, Idx: 400, Training Loss: 0.1376, Training Accuracy:  93.75%\n","Epoch: 100, Train Loss: 0.101, Train Acc: 96.66%, Val. Loss: 0.376833, Val. Acc: 81.60%\n","(train_model) Epoch: 101, Idx: 100, Training Loss: 0.0824, Training Accuracy:  93.75%\n","(train_model) Epoch: 101, Idx: 200, Training Loss: 0.2854, Training Accuracy:  87.50%\n","(train_model) Epoch: 101, Idx: 300, Training Loss: 0.1158, Training Accuracy:  93.75%\n","(train_model) Epoch: 101, Idx: 400, Training Loss: 0.1513, Training Accuracy:  100.00%\n","Epoch: 101, Train Loss: 0.110, Train Acc: 96.06%, Val. Loss: 0.298465, Val. Acc: 88.06%\n","(train_model) Epoch: 102, Idx: 100, Training Loss: 0.0255, Training Accuracy:  100.00%\n","(train_model) Epoch: 102, Idx: 200, Training Loss: 0.2864, Training Accuracy:  93.75%\n","(train_model) Epoch: 102, Idx: 300, Training Loss: 0.1724, Training Accuracy:  93.75%\n","(train_model) Epoch: 102, Idx: 400, Training Loss: 0.6294, Training Accuracy:  81.25%\n","Epoch: 102, Train Loss: 0.108, Train Acc: 96.58%, Val. Loss: 0.390950, Val. Acc: 76.20%\n","(train_model) Epoch: 103, Idx: 100, Training Loss: 0.5399, Training Accuracy:  87.50%\n","(train_model) Epoch: 103, Idx: 200, Training Loss: 0.0212, Training Accuracy:  100.00%\n","(train_model) Epoch: 103, Idx: 300, Training Loss: 0.0434, Training Accuracy:  100.00%\n","(train_model) Epoch: 103, Idx: 400, Training Loss: 0.1555, Training Accuracy:  87.50%\n","Epoch: 103, Train Loss: 0.104, Train Acc: 96.54%, Val. Loss: 0.308751, Val. Acc: 86.48%\n","(train_model) Epoch: 104, Idx: 100, Training Loss: 0.0502, Training Accuracy:  100.00%\n","(train_model) Epoch: 104, Idx: 200, Training Loss: 0.0079, Training Accuracy:  100.00%\n","(train_model) Epoch: 104, Idx: 300, Training Loss: 0.3302, Training Accuracy:  81.25%\n","(train_model) Epoch: 104, Idx: 400, Training Loss: 0.1236, Training Accuracy:  93.75%\n","Epoch: 104, Train Loss: 0.118, Train Acc: 96.15%, Val. Loss: 0.321131, Val. Acc: 87.82%\n","(train_model) Epoch: 105, Idx: 100, Training Loss: 0.0167, Training Accuracy:  100.00%\n","(train_model) Epoch: 105, Idx: 200, Training Loss: 0.0892, Training Accuracy:  93.75%\n","(train_model) Epoch: 105, Idx: 300, Training Loss: 0.0701, Training Accuracy:  100.00%\n","(train_model) Epoch: 105, Idx: 400, Training Loss: 0.4366, Training Accuracy:  93.75%\n","Epoch: 105, Train Loss: 0.114, Train Acc: 95.98%, Val. Loss: 0.313619, Val. Acc: 84.86%\n","(train_model) Epoch: 106, Idx: 100, Training Loss: 0.1806, Training Accuracy:  93.75%\n","(train_model) Epoch: 106, Idx: 200, Training Loss: 0.0080, Training Accuracy:  100.00%\n","(train_model) Epoch: 106, Idx: 300, Training Loss: 0.3605, Training Accuracy:  87.50%\n","(train_model) Epoch: 106, Idx: 400, Training Loss: 0.1431, Training Accuracy:  93.75%\n","Epoch: 106, Train Loss: 0.086, Train Acc: 97.12%, Val. Loss: 0.314463, Val. Acc: 85.20%\n","(train_model) Epoch: 107, Idx: 100, Training Loss: 0.0990, Training Accuracy:  93.75%\n","(train_model) Epoch: 107, Idx: 200, Training Loss: 0.1962, Training Accuracy:  93.75%\n","(train_model) Epoch: 107, Idx: 300, Training Loss: 0.0821, Training Accuracy:  100.00%\n","(train_model) Epoch: 107, Idx: 400, Training Loss: 0.1241, Training Accuracy:  93.75%\n","Epoch: 107, Train Loss: 0.098, Train Acc: 96.46%, Val. Loss: 0.317823, Val. Acc: 88.22%\n","(train_model) Epoch: 108, Idx: 100, Training Loss: 0.0986, Training Accuracy:  93.75%\n","(train_model) Epoch: 108, Idx: 200, Training Loss: 0.0249, Training Accuracy:  100.00%\n","(train_model) Epoch: 108, Idx: 300, Training Loss: 0.3338, Training Accuracy:  87.50%\n","(train_model) Epoch: 108, Idx: 400, Training Loss: 0.1286, Training Accuracy:  93.75%\n","Epoch: 108, Train Loss: 0.113, Train Acc: 96.07%, Val. Loss: 0.331125, Val. Acc: 82.16%\n","(train_model) Epoch: 109, Idx: 100, Training Loss: 0.2444, Training Accuracy:  93.75%\n","(train_model) Epoch: 109, Idx: 200, Training Loss: 0.0160, Training Accuracy:  100.00%\n","(train_model) Epoch: 109, Idx: 300, Training Loss: 0.1938, Training Accuracy:  93.75%\n","(train_model) Epoch: 109, Idx: 400, Training Loss: 0.0689, Training Accuracy:  100.00%\n","Epoch: 109, Train Loss: 0.101, Train Acc: 96.61%, Val. Loss: 0.331496, Val. Acc: 83.06%\n","(train_model) Epoch: 110, Idx: 100, Training Loss: 0.0078, Training Accuracy:  100.00%\n","(train_model) Epoch: 110, Idx: 200, Training Loss: 0.0056, Training Accuracy:  100.00%\n","(train_model) Epoch: 110, Idx: 300, Training Loss: 0.3292, Training Accuracy:  93.75%\n","(train_model) Epoch: 110, Idx: 400, Training Loss: 0.2555, Training Accuracy:  87.50%\n","Epoch: 110, Train Loss: 0.092, Train Acc: 96.65%, Val. Loss: 0.339023, Val. Acc: 83.86%\n","(train_model) Epoch: 111, Idx: 100, Training Loss: 0.0141, Training Accuracy:  100.00%\n","(train_model) Epoch: 111, Idx: 200, Training Loss: 0.1750, Training Accuracy:  87.50%\n","(train_model) Epoch: 111, Idx: 300, Training Loss: 0.1806, Training Accuracy:  93.75%\n","(train_model) Epoch: 111, Idx: 400, Training Loss: 0.1204, Training Accuracy:  93.75%\n","Epoch: 111, Train Loss: 0.106, Train Acc: 96.36%, Val. Loss: 0.316797, Val. Acc: 87.38%\n","(train_model) Epoch: 112, Idx: 100, Training Loss: 0.0274, Training Accuracy:  100.00%\n","(train_model) Epoch: 112, Idx: 200, Training Loss: 0.0074, Training Accuracy:  100.00%\n","(train_model) Epoch: 112, Idx: 300, Training Loss: 0.0507, Training Accuracy:  100.00%\n","(train_model) Epoch: 112, Idx: 400, Training Loss: 0.1084, Training Accuracy:  100.00%\n","Epoch: 112, Train Loss: 0.101, Train Acc: 96.68%, Val. Loss: 0.611641, Val. Acc: 82.92%\n","(train_model) Epoch: 113, Idx: 100, Training Loss: 0.0344, Training Accuracy:  100.00%\n","(train_model) Epoch: 113, Idx: 200, Training Loss: 0.0378, Training Accuracy:  100.00%\n","(train_model) Epoch: 113, Idx: 300, Training Loss: 0.0108, Training Accuracy:  100.00%\n","(train_model) Epoch: 113, Idx: 400, Training Loss: 0.0900, Training Accuracy:  93.75%\n","Epoch: 113, Train Loss: 0.097, Train Acc: 96.79%, Val. Loss: 0.326582, Val. Acc: 84.92%\n","(train_model) Epoch: 114, Idx: 100, Training Loss: 0.0205, Training Accuracy:  100.00%\n","(train_model) Epoch: 114, Idx: 200, Training Loss: 0.0609, Training Accuracy:  100.00%\n","(train_model) Epoch: 114, Idx: 300, Training Loss: 0.1885, Training Accuracy:  93.75%\n","(train_model) Epoch: 114, Idx: 400, Training Loss: 0.0875, Training Accuracy:  100.00%\n","Epoch: 114, Train Loss: 0.095, Train Acc: 96.85%, Val. Loss: 0.306223, Val. Acc: 86.18%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 115, Idx: 100, Training Loss: 0.0060, Training Accuracy:  100.00%\n","(train_model) Epoch: 115, Idx: 200, Training Loss: 0.0254, Training Accuracy:  100.00%\n","(train_model) Epoch: 115, Idx: 300, Training Loss: 0.1602, Training Accuracy:  87.50%\n","(train_model) Epoch: 115, Idx: 400, Training Loss: 0.3261, Training Accuracy:  87.50%\n","Epoch: 115, Train Loss: 0.101, Train Acc: 96.65%, Val. Loss: 0.403653, Val. Acc: 79.54%\n","(train_model) Epoch: 116, Idx: 100, Training Loss: 0.0449, Training Accuracy:  100.00%\n","(train_model) Epoch: 116, Idx: 200, Training Loss: 0.7427, Training Accuracy:  87.50%\n","(train_model) Epoch: 116, Idx: 300, Training Loss: 0.2418, Training Accuracy:  87.50%\n","(train_model) Epoch: 116, Idx: 400, Training Loss: 0.3291, Training Accuracy:  93.75%\n","Epoch: 116, Train Loss: 0.109, Train Acc: 96.20%, Val. Loss: 0.338277, Val. Acc: 87.78%\n","(train_model) Epoch: 117, Idx: 100, Training Loss: 0.0387, Training Accuracy:  100.00%\n","(train_model) Epoch: 117, Idx: 200, Training Loss: 0.0320, Training Accuracy:  100.00%\n","(train_model) Epoch: 117, Idx: 300, Training Loss: 0.2104, Training Accuracy:  87.50%\n","(train_model) Epoch: 117, Idx: 400, Training Loss: 0.0215, Training Accuracy:  100.00%\n","Epoch: 117, Train Loss: 0.092, Train Acc: 97.03%, Val. Loss: 0.344808, Val. Acc: 82.98%\n","(train_model) Epoch: 118, Idx: 100, Training Loss: 0.0445, Training Accuracy:  100.00%\n","(train_model) Epoch: 118, Idx: 200, Training Loss: 0.2274, Training Accuracy:  93.75%\n","(train_model) Epoch: 118, Idx: 300, Training Loss: 0.0032, Training Accuracy:  100.00%\n","(train_model) Epoch: 118, Idx: 400, Training Loss: 0.2843, Training Accuracy:  93.75%\n","Epoch: 118, Train Loss: 0.110, Train Acc: 96.46%, Val. Loss: 0.305421, Val. Acc: 87.96%\n","(train_model) Epoch: 119, Idx: 100, Training Loss: 0.0132, Training Accuracy:  100.00%\n","(train_model) Epoch: 119, Idx: 200, Training Loss: 0.0873, Training Accuracy:  93.75%\n","(train_model) Epoch: 119, Idx: 300, Training Loss: 0.0166, Training Accuracy:  100.00%\n","(train_model) Epoch: 119, Idx: 400, Training Loss: 0.1678, Training Accuracy:  87.50%\n","Epoch: 119, Train Loss: 0.102, Train Acc: 96.29%, Val. Loss: 0.446774, Val. Acc: 74.90%\n","(train_model) Epoch: 120, Idx: 100, Training Loss: 0.0069, Training Accuracy:  100.00%\n","(train_model) Epoch: 120, Idx: 200, Training Loss: 0.3281, Training Accuracy:  93.75%\n","(train_model) Epoch: 120, Idx: 300, Training Loss: 0.3035, Training Accuracy:  93.75%\n","(train_model) Epoch: 120, Idx: 400, Training Loss: 0.1863, Training Accuracy:  93.75%\n","Epoch: 120, Train Loss: 0.115, Train Acc: 96.22%, Val. Loss: 0.413118, Val. Acc: 82.96%\n","(train_model) Epoch: 121, Idx: 100, Training Loss: 0.0322, Training Accuracy:  100.00%\n","(train_model) Epoch: 121, Idx: 200, Training Loss: 0.0333, Training Accuracy:  100.00%\n","(train_model) Epoch: 121, Idx: 300, Training Loss: 0.1628, Training Accuracy:  87.50%\n","(train_model) Epoch: 121, Idx: 400, Training Loss: 0.3218, Training Accuracy:  87.50%\n","Epoch: 121, Train Loss: 0.150, Train Acc: 94.66%, Val. Loss: 0.317231, Val. Acc: 87.08%\n","(train_model) Epoch: 122, Idx: 100, Training Loss: 0.3649, Training Accuracy:  93.75%\n","(train_model) Epoch: 122, Idx: 200, Training Loss: 0.1161, Training Accuracy:  93.75%\n","(train_model) Epoch: 122, Idx: 300, Training Loss: 0.0203, Training Accuracy:  100.00%\n","(train_model) Epoch: 122, Idx: 400, Training Loss: 0.0582, Training Accuracy:  100.00%\n","Epoch: 122, Train Loss: 0.103, Train Acc: 96.51%, Val. Loss: 0.430213, Val. Acc: 78.26%\n","(train_model) Epoch: 123, Idx: 100, Training Loss: 0.0168, Training Accuracy:  100.00%\n","(train_model) Epoch: 123, Idx: 200, Training Loss: 0.0767, Training Accuracy:  100.00%\n","(train_model) Epoch: 123, Idx: 300, Training Loss: 0.1853, Training Accuracy:  93.75%\n","(train_model) Epoch: 123, Idx: 400, Training Loss: 0.1439, Training Accuracy:  93.75%\n","Epoch: 123, Train Loss: 0.121, Train Acc: 95.95%, Val. Loss: 0.371788, Val. Acc: 80.88%\n","(train_model) Epoch: 124, Idx: 100, Training Loss: 0.4466, Training Accuracy:  93.75%\n","(train_model) Epoch: 124, Idx: 200, Training Loss: 0.0222, Training Accuracy:  100.00%\n","(train_model) Epoch: 124, Idx: 300, Training Loss: 0.1117, Training Accuracy:  93.75%\n","(train_model) Epoch: 124, Idx: 400, Training Loss: 0.1482, Training Accuracy:  93.75%\n","Epoch: 124, Train Loss: 0.106, Train Acc: 96.35%, Val. Loss: 0.382543, Val. Acc: 83.10%\n","(train_model) Epoch: 125, Idx: 100, Training Loss: 0.0228, Training Accuracy:  100.00%\n","(train_model) Epoch: 125, Idx: 200, Training Loss: 0.4291, Training Accuracy:  87.50%\n","(train_model) Epoch: 125, Idx: 300, Training Loss: 0.2074, Training Accuracy:  93.75%\n","(train_model) Epoch: 125, Idx: 400, Training Loss: 0.0792, Training Accuracy:  93.75%\n","Epoch: 125, Train Loss: 0.105, Train Acc: 96.85%, Val. Loss: 0.398832, Val. Acc: 79.10%\n","(train_model) Epoch: 126, Idx: 100, Training Loss: 0.0994, Training Accuracy:  93.75%\n","(train_model) Epoch: 126, Idx: 200, Training Loss: 0.0313, Training Accuracy:  100.00%\n","(train_model) Epoch: 126, Idx: 300, Training Loss: 0.1097, Training Accuracy:  93.75%\n","(train_model) Epoch: 126, Idx: 400, Training Loss: 0.2870, Training Accuracy:  93.75%\n","Epoch: 126, Train Loss: 0.128, Train Acc: 95.78%, Val. Loss: 0.453845, Val. Acc: 72.54%\n","(train_model) Epoch: 127, Idx: 100, Training Loss: 0.0532, Training Accuracy:  100.00%\n","(train_model) Epoch: 127, Idx: 200, Training Loss: 0.2354, Training Accuracy:  93.75%\n","(train_model) Epoch: 127, Idx: 300, Training Loss: 0.1315, Training Accuracy:  87.50%\n","(train_model) Epoch: 127, Idx: 400, Training Loss: 0.0496, Training Accuracy:  100.00%\n","Epoch: 127, Train Loss: 0.117, Train Acc: 95.69%, Val. Loss: 0.569236, Val. Acc: 63.72%\n","(train_model) Epoch: 128, Idx: 100, Training Loss: 0.3826, Training Accuracy:  87.50%\n","(train_model) Epoch: 128, Idx: 200, Training Loss: 0.5781, Training Accuracy:  87.50%\n","(train_model) Epoch: 128, Idx: 300, Training Loss: 0.4462, Training Accuracy:  87.50%\n","(train_model) Epoch: 128, Idx: 400, Training Loss: 0.2385, Training Accuracy:  87.50%\n","Epoch: 128, Train Loss: 0.125, Train Acc: 95.62%, Val. Loss: 0.416543, Val. Acc: 82.42%\n","(train_model) Epoch: 129, Idx: 100, Training Loss: 0.0692, Training Accuracy:  100.00%\n","(train_model) Epoch: 129, Idx: 200, Training Loss: 0.1647, Training Accuracy:  93.75%\n","(train_model) Epoch: 129, Idx: 300, Training Loss: 0.1232, Training Accuracy:  93.75%\n","(train_model) Epoch: 129, Idx: 400, Training Loss: 0.1939, Training Accuracy:  93.75%\n","Epoch: 129, Train Loss: 0.110, Train Acc: 96.50%, Val. Loss: 0.316025, Val. Acc: 84.88%\n","(train_model) Epoch: 130, Idx: 100, Training Loss: 0.1536, Training Accuracy:  93.75%\n","(train_model) Epoch: 130, Idx: 200, Training Loss: 0.4793, Training Accuracy:  87.50%\n","(train_model) Epoch: 130, Idx: 300, Training Loss: 0.4124, Training Accuracy:  87.50%\n","(train_model) Epoch: 130, Idx: 400, Training Loss: 0.0139, Training Accuracy:  100.00%\n","Epoch: 130, Train Loss: 0.107, Train Acc: 96.50%, Val. Loss: 0.293939, Val. Acc: 86.56%\n","(train_model) Epoch: 131, Idx: 100, Training Loss: 0.3370, Training Accuracy:  93.75%\n","(train_model) Epoch: 131, Idx: 200, Training Loss: 0.0141, Training Accuracy:  100.00%\n","(train_model) Epoch: 131, Idx: 300, Training Loss: 0.7502, Training Accuracy:  81.25%\n","(train_model) Epoch: 131, Idx: 400, Training Loss: 0.1146, Training Accuracy:  93.75%\n","Epoch: 131, Train Loss: 0.087, Train Acc: 96.99%, Val. Loss: 0.431199, Val. Acc: 81.56%\n","(train_model) Epoch: 132, Idx: 100, Training Loss: 0.0235, Training Accuracy:  100.00%\n","(train_model) Epoch: 132, Idx: 200, Training Loss: 0.0069, Training Accuracy:  100.00%\n","(train_model) Epoch: 132, Idx: 300, Training Loss: 0.1627, Training Accuracy:  93.75%\n","(train_model) Epoch: 132, Idx: 400, Training Loss: 0.2920, Training Accuracy:  87.50%\n","Epoch: 132, Train Loss: 0.108, Train Acc: 96.32%, Val. Loss: 0.311663, Val. Acc: 86.00%\n","(train_model) Epoch: 133, Idx: 100, Training Loss: 0.0586, Training Accuracy:  100.00%\n","(train_model) Epoch: 133, Idx: 200, Training Loss: 0.5365, Training Accuracy:  87.50%\n","(train_model) Epoch: 133, Idx: 300, Training Loss: 0.2113, Training Accuracy:  93.75%\n","(train_model) Epoch: 133, Idx: 400, Training Loss: 0.2836, Training Accuracy:  93.75%\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 133, Train Loss: 0.085, Train Acc: 96.95%, Val. Loss: 0.284352, Val. Acc: 87.92%\n","(train_model) Epoch: 134, Idx: 100, Training Loss: 0.1420, Training Accuracy:  87.50%\n","(train_model) Epoch: 134, Idx: 200, Training Loss: 0.0998, Training Accuracy:  93.75%\n","(train_model) Epoch: 134, Idx: 300, Training Loss: 0.0221, Training Accuracy:  100.00%\n","(train_model) Epoch: 134, Idx: 400, Training Loss: 0.5382, Training Accuracy:  87.50%\n","Epoch: 134, Train Loss: 0.079, Train Acc: 97.45%, Val. Loss: 0.302090, Val. Acc: 87.48%\n","(train_model) Epoch: 135, Idx: 100, Training Loss: 0.0767, Training Accuracy:  93.75%\n","(train_model) Epoch: 135, Idx: 200, Training Loss: 0.0133, Training Accuracy:  100.00%\n","(train_model) Epoch: 135, Idx: 300, Training Loss: 0.0770, Training Accuracy:  93.75%\n","(train_model) Epoch: 135, Idx: 400, Training Loss: 0.0657, Training Accuracy:  93.75%\n","Epoch: 135, Train Loss: 0.086, Train Acc: 97.23%, Val. Loss: 0.334340, Val. Acc: 86.68%\n","(train_model) Epoch: 136, Idx: 100, Training Loss: 0.1536, Training Accuracy:  93.75%\n","(train_model) Epoch: 136, Idx: 200, Training Loss: 0.1737, Training Accuracy:  93.75%\n","(train_model) Epoch: 136, Idx: 300, Training Loss: 0.0813, Training Accuracy:  93.75%\n","(train_model) Epoch: 136, Idx: 400, Training Loss: 0.0895, Training Accuracy:  100.00%\n","Epoch: 136, Train Loss: 0.092, Train Acc: 96.96%, Val. Loss: 0.307143, Val. Acc: 86.24%\n","(train_model) Epoch: 137, Idx: 100, Training Loss: 0.1047, Training Accuracy:  93.75%\n","(train_model) Epoch: 137, Idx: 200, Training Loss: 0.4368, Training Accuracy:  87.50%\n","(train_model) Epoch: 137, Idx: 300, Training Loss: 0.0489, Training Accuracy:  100.00%\n","(train_model) Epoch: 137, Idx: 400, Training Loss: 0.1856, Training Accuracy:  93.75%\n","Epoch: 137, Train Loss: 0.087, Train Acc: 97.13%, Val. Loss: 0.299947, Val. Acc: 88.18%\n","(train_model) Epoch: 138, Idx: 100, Training Loss: 0.0507, Training Accuracy:  100.00%\n","(train_model) Epoch: 138, Idx: 200, Training Loss: 0.1891, Training Accuracy:  93.75%\n","(train_model) Epoch: 138, Idx: 300, Training Loss: 0.1513, Training Accuracy:  93.75%\n","(train_model) Epoch: 138, Idx: 400, Training Loss: 0.0409, Training Accuracy:  100.00%\n","Epoch: 138, Train Loss: 0.084, Train Acc: 97.14%, Val. Loss: 0.300230, Val. Acc: 87.64%\n","(train_model) Epoch: 139, Idx: 100, Training Loss: 0.0113, Training Accuracy:  100.00%\n","(train_model) Epoch: 139, Idx: 200, Training Loss: 0.1947, Training Accuracy:  93.75%\n","(train_model) Epoch: 139, Idx: 300, Training Loss: 0.0164, Training Accuracy:  100.00%\n","(train_model) Epoch: 139, Idx: 400, Training Loss: 0.2190, Training Accuracy:  87.50%\n","Epoch: 139, Train Loss: 0.069, Train Acc: 97.62%, Val. Loss: 0.344573, Val. Acc: 87.32%\n","(train_model) Epoch: 140, Idx: 100, Training Loss: 0.0430, Training Accuracy:  100.00%\n","(train_model) Epoch: 140, Idx: 200, Training Loss: 0.6473, Training Accuracy:  81.25%\n","(train_model) Epoch: 140, Idx: 300, Training Loss: 0.1783, Training Accuracy:  93.75%\n","(train_model) Epoch: 140, Idx: 400, Training Loss: 0.1291, Training Accuracy:  93.75%\n","Epoch: 140, Train Loss: 0.103, Train Acc: 96.57%, Val. Loss: 0.320312, Val. Acc: 86.18%\n","(train_model) Epoch: 141, Idx: 100, Training Loss: 0.3396, Training Accuracy:  93.75%\n","(train_model) Epoch: 141, Idx: 200, Training Loss: 0.1910, Training Accuracy:  93.75%\n","(train_model) Epoch: 141, Idx: 300, Training Loss: 0.0522, Training Accuracy:  93.75%\n","(train_model) Epoch: 141, Idx: 400, Training Loss: 0.0310, Training Accuracy:  100.00%\n","Epoch: 141, Train Loss: 0.081, Train Acc: 97.35%, Val. Loss: 0.288375, Val. Acc: 87.84%\n","(train_model) Epoch: 142, Idx: 100, Training Loss: 0.0802, Training Accuracy:  93.75%\n","(train_model) Epoch: 142, Idx: 200, Training Loss: 0.1396, Training Accuracy:  87.50%\n","(train_model) Epoch: 142, Idx: 300, Training Loss: 0.0100, Training Accuracy:  100.00%\n","(train_model) Epoch: 142, Idx: 400, Training Loss: 0.0092, Training Accuracy:  100.00%\n","Epoch: 142, Train Loss: 0.079, Train Acc: 97.31%, Val. Loss: 0.309053, Val. Acc: 86.68%\n","(train_model) Epoch: 143, Idx: 100, Training Loss: 0.0004, Training Accuracy:  100.00%\n","(train_model) Epoch: 143, Idx: 200, Training Loss: 0.1167, Training Accuracy:  93.75%\n","(train_model) Epoch: 143, Idx: 300, Training Loss: 0.0081, Training Accuracy:  100.00%\n","(train_model) Epoch: 143, Idx: 400, Training Loss: 0.3727, Training Accuracy:  81.25%\n","Epoch: 143, Train Loss: 0.080, Train Acc: 97.25%, Val. Loss: 0.330481, Val. Acc: 87.34%\n","(train_model) Epoch: 144, Idx: 100, Training Loss: 0.0259, Training Accuracy:  100.00%\n","(train_model) Epoch: 144, Idx: 200, Training Loss: 0.0977, Training Accuracy:  93.75%\n","(train_model) Epoch: 144, Idx: 300, Training Loss: 0.0490, Training Accuracy:  100.00%\n","(train_model) Epoch: 144, Idx: 400, Training Loss: 0.1232, Training Accuracy:  93.75%\n","Epoch: 144, Train Loss: 0.077, Train Acc: 97.55%, Val. Loss: 0.315967, Val. Acc: 85.12%\n","(train_model) Epoch: 145, Idx: 100, Training Loss: 0.0821, Training Accuracy:  93.75%\n","(train_model) Epoch: 145, Idx: 200, Training Loss: 0.0522, Training Accuracy:  100.00%\n","(train_model) Epoch: 145, Idx: 300, Training Loss: 0.0686, Training Accuracy:  93.75%\n","(train_model) Epoch: 145, Idx: 400, Training Loss: 0.1860, Training Accuracy:  93.75%\n","Epoch: 145, Train Loss: 0.083, Train Acc: 97.25%, Val. Loss: 0.593635, Val. Acc: 77.56%\n","(train_model) Epoch: 146, Idx: 100, Training Loss: 0.0775, Training Accuracy:  100.00%\n","(train_model) Epoch: 146, Idx: 200, Training Loss: 0.0416, Training Accuracy:  100.00%\n","(train_model) Epoch: 146, Idx: 300, Training Loss: 0.0153, Training Accuracy:  100.00%\n","(train_model) Epoch: 146, Idx: 400, Training Loss: 0.0033, Training Accuracy:  100.00%\n","Epoch: 146, Train Loss: 0.083, Train Acc: 97.13%, Val. Loss: 0.306573, Val. Acc: 86.78%\n","(train_model) Epoch: 147, Idx: 100, Training Loss: 0.0116, Training Accuracy:  100.00%\n","(train_model) Epoch: 147, Idx: 200, Training Loss: 0.0416, Training Accuracy:  100.00%\n","(train_model) Epoch: 147, Idx: 300, Training Loss: 0.0068, Training Accuracy:  100.00%\n","(train_model) Epoch: 147, Idx: 400, Training Loss: 0.0166, Training Accuracy:  100.00%\n","Epoch: 147, Train Loss: 0.073, Train Acc: 97.57%, Val. Loss: 0.286099, Val. Acc: 87.32%\n","(train_model) Epoch: 148, Idx: 100, Training Loss: 0.4944, Training Accuracy:  93.75%\n","(train_model) Epoch: 148, Idx: 200, Training Loss: 0.0739, Training Accuracy:  93.75%\n","(train_model) Epoch: 148, Idx: 300, Training Loss: 0.0078, Training Accuracy:  100.00%\n","(train_model) Epoch: 148, Idx: 400, Training Loss: 0.0603, Training Accuracy:  93.75%\n","Epoch: 148, Train Loss: 0.058, Train Acc: 98.10%, Val. Loss: 0.303800, Val. Acc: 86.80%\n","(train_model) Epoch: 149, Idx: 100, Training Loss: 0.0768, Training Accuracy:  100.00%\n","(train_model) Epoch: 149, Idx: 200, Training Loss: 0.2938, Training Accuracy:  93.75%\n","(train_model) Epoch: 149, Idx: 300, Training Loss: 0.0138, Training Accuracy:  100.00%\n","(train_model) Epoch: 149, Idx: 400, Training Loss: 0.0099, Training Accuracy:  100.00%\n","Epoch: 149, Train Loss: 0.076, Train Acc: 97.51%, Val. Loss: 0.288887, Val. Acc: 88.08%\n","(train_model) Epoch: 150, Idx: 100, Training Loss: 0.1231, Training Accuracy:  93.75%\n","(train_model) Epoch: 150, Idx: 200, Training Loss: 0.0041, Training Accuracy:  100.00%\n","(train_model) Epoch: 150, Idx: 300, Training Loss: 0.1472, Training Accuracy:  87.50%\n","(train_model) Epoch: 150, Idx: 400, Training Loss: 0.0131, Training Accuracy:  100.00%\n","Epoch: 150, Train Loss: 0.070, Train Acc: 97.65%, Val. Loss: 0.332782, Val. Acc: 87.40%\n","Best train acc: 98.10%, best val acc: 90.08%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iloBQLEWuex0","colab":{}},"source":["# test_loss, test_acc = eval_model(model, test_iter)\n","# print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"E95ap62wyvnV","colab":{}},"source":["# ''' Let us now predict on a single sentence just for the testing purpose. '''\n","# test_sen1 = \"This is one of the best creation of Nolan. I can say, it's his magnum opus. Loved the soundtrack and especially those creative dialogues.\"\n","# test_sen2 = \"Ohh, such a ridiculous movie. Not gonna recommend it to anyone. Complete waste of time and money.\"\n","\n","# # format sentence into a 1 x max_seq_len tokenized and padded np array, then convert to tensor\n","# # test_sen1 = ...\n","\n","# test_sen = np.asarray(test_sen1)\n","# test_sen = torch.LongTensor(test_sen)\n","\n","# test_tensor = Variable(test_sen, volatile=True)\n","# test_tensor = test_tensor.cuda()\n","\n","# model.eval()\n","# output = model(test_tensor, 1)\n","# print(output)\n","# out = F.softmax(output, 1)\n","# print(out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JMnxaAPe2WC6","outputId":"2c4b968b-ec99-4a91-afa9-90244c418054","colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["plt.plot(train_acc_history, label='Training Accuracy')\n","plt.plot(val_acc_history, label='Validation Accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oR_LzZIY22FE","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zEbA_7WOPSbd"},"source":["## Load Cornell Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZuaTn9nkPSbe","colab":{}},"source":["# main training dataset\n","\n","cbert_train_url = 'https://raw.githubusercontent.com/lcassels/cbert_aug/develop/datasets/cornell/train.tsv'\n","cbert_test_url = 'https://raw.githubusercontent.com/lcassels/cbert_aug/develop/datasets/cornell/test.tsv'\n","\n","cbert_train = pd.read_csv(cbert_train_url, sep='\\t')\n","cbert_test = pd.read_csv(cbert_test_url, sep='\\t')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wdn5ZBbzPSbh","colab":{}},"source":["cbert_train, cbert_val = train_test_split(cbert_train, test_size=0.1, random_state=0, shuffle=True)\n","cbert_train.reset_index(inplace=True)\n","cbert_train.drop(columns=[\"index\"], inplace=True)\n","cbert_val.reset_index(inplace=True)\n","cbert_val.drop(columns=[\"index\"], inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_t7IxkmKPSbk","outputId":"68c73fa9-69be-4f85-96bc-028bdf172953","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["cbert_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>but when those worlds collide , taking the liv...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>sus problemas empiezan cuando bigardo , un pre...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>it's unfortunate that wallace , who wrote gibs...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>dr . david gale , an advocate of eliminating t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>they're just a couple of cops in copmovieland ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label\n","0  but when those worlds collide , taking the liv...      1\n","1  sus problemas empiezan cuando bigardo , un pre...      1\n","2  it's unfortunate that wallace , who wrote gibs...      0\n","3  dr . david gale , an advocate of eliminating t...      1\n","4  they're just a couple of cops in copmovieland ...      0"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7FIhACVQPZY6","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gd3v4xXWPZtU"},"source":["## Train on Cornell dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WuOwlE39PZtV","colab":{}},"source":["# Parameters\n","params = {'batch_size': batch_size,\n","          'shuffle': False,\n","          'drop_last': True}\n","\n","training_loader = DataLoader(Intents(cbert_train), **params)\n","testing_loader = DataLoader(Intents(cbert_test), **params)\n","val_loader = DataLoader(Intents(cbert_val), **params)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"b7kjdsdXPZtY","colab":{}},"source":["model = LSTMClassifierRoberta(batch_size, output_size, hidden_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FdCy8kxIPZta","outputId":"a6b6bac5-1d7f-4517-c354-1f7fde7c50bd","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["train_acc_history = []\n","val_acc_history = []\n","for epoch in range(150):\n","    train_loss, train_acc = train_model(model, training_loader, epoch)\n","    val_loss, val_acc = eval_model(model, val_loader)\n","    train_acc_history.append(train_acc)\n","    val_acc_history.append(val_acc)\n","\n","    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n","\n","print(f'Best train acc: {max(train_acc_history):.2f}%, best val acc: {max(val_acc_history):.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(train_model) Epoch: 1, Idx: 100, Training Loss: 0.6959, Training Accuracy:  50.00%\n","(train_model) Epoch: 1, Idx: 200, Training Loss: 0.7134, Training Accuracy:  43.75%\n","(train_model) Epoch: 1, Idx: 300, Training Loss: 0.7343, Training Accuracy:  37.50%\n","(train_model) Epoch: 1, Idx: 400, Training Loss: 0.6525, Training Accuracy:  62.50%\n","Epoch: 01, Train Loss: 0.693, Train Acc: 52.17%, Val. Loss: 0.687580, Val. Acc: 52.62%\n","(train_model) Epoch: 2, Idx: 100, Training Loss: 0.6267, Training Accuracy:  87.50%\n","(train_model) Epoch: 2, Idx: 200, Training Loss: 0.7234, Training Accuracy:  37.50%\n","(train_model) Epoch: 2, Idx: 300, Training Loss: 0.7155, Training Accuracy:  37.50%\n","(train_model) Epoch: 2, Idx: 400, Training Loss: 0.6572, Training Accuracy:  68.75%\n","Epoch: 02, Train Loss: 0.686, Train Acc: 54.22%, Val. Loss: 0.686959, Val. Acc: 52.66%\n","(train_model) Epoch: 3, Idx: 100, Training Loss: 0.6568, Training Accuracy:  68.75%\n","(train_model) Epoch: 3, Idx: 200, Training Loss: 0.6941, Training Accuracy:  43.75%\n","(train_model) Epoch: 3, Idx: 300, Training Loss: 0.7195, Training Accuracy:  37.50%\n","(train_model) Epoch: 3, Idx: 400, Training Loss: 0.6275, Training Accuracy:  68.75%\n","Epoch: 03, Train Loss: 0.679, Train Acc: 55.92%, Val. Loss: 0.645574, Val. Acc: 62.88%\n","(train_model) Epoch: 4, Idx: 100, Training Loss: 0.6644, Training Accuracy:  62.50%\n","(train_model) Epoch: 4, Idx: 200, Training Loss: 0.7271, Training Accuracy:  56.25%\n","(train_model) Epoch: 4, Idx: 300, Training Loss: 0.7274, Training Accuracy:  50.00%\n","(train_model) Epoch: 4, Idx: 400, Training Loss: 0.6271, Training Accuracy:  68.75%\n","Epoch: 04, Train Loss: 0.668, Train Acc: 59.29%, Val. Loss: 0.684565, Val. Acc: 52.00%\n","(train_model) Epoch: 5, Idx: 100, Training Loss: 0.6126, Training Accuracy:  68.75%\n","(train_model) Epoch: 5, Idx: 200, Training Loss: 0.6400, Training Accuracy:  68.75%\n","(train_model) Epoch: 5, Idx: 300, Training Loss: 0.9398, Training Accuracy:  43.75%\n","(train_model) Epoch: 5, Idx: 400, Training Loss: 0.6356, Training Accuracy:  81.25%\n","Epoch: 05, Train Loss: 0.669, Train Acc: 59.49%, Val. Loss: 0.621647, Val. Acc: 71.64%\n","(train_model) Epoch: 6, Idx: 100, Training Loss: 0.6825, Training Accuracy:  50.00%\n","(train_model) Epoch: 6, Idx: 200, Training Loss: 0.6442, Training Accuracy:  62.50%\n","(train_model) Epoch: 6, Idx: 300, Training Loss: 0.5364, Training Accuracy:  81.25%\n","(train_model) Epoch: 6, Idx: 400, Training Loss: 0.7773, Training Accuracy:  43.75%\n","Epoch: 06, Train Loss: 0.632, Train Acc: 66.33%, Val. Loss: 0.593883, Val. Acc: 64.64%\n","(train_model) Epoch: 7, Idx: 100, Training Loss: 0.7306, Training Accuracy:  56.25%\n","(train_model) Epoch: 7, Idx: 200, Training Loss: 0.5981, Training Accuracy:  62.50%\n","(train_model) Epoch: 7, Idx: 300, Training Loss: 0.7418, Training Accuracy:  50.00%\n","(train_model) Epoch: 7, Idx: 400, Training Loss: 0.7152, Training Accuracy:  62.50%\n","Epoch: 07, Train Loss: 0.576, Train Acc: 71.55%, Val. Loss: 0.535838, Val. Acc: 74.86%\n","(train_model) Epoch: 8, Idx: 100, Training Loss: 0.6788, Training Accuracy:  56.25%\n","(train_model) Epoch: 8, Idx: 200, Training Loss: 0.6406, Training Accuracy:  62.50%\n","(train_model) Epoch: 8, Idx: 300, Training Loss: 0.3346, Training Accuracy:  87.50%\n","(train_model) Epoch: 8, Idx: 400, Training Loss: 0.7188, Training Accuracy:  62.50%\n","Epoch: 08, Train Loss: 0.498, Train Acc: 76.41%, Val. Loss: 0.530037, Val. Acc: 71.96%\n","(train_model) Epoch: 9, Idx: 100, Training Loss: 0.5295, Training Accuracy:  68.75%\n","(train_model) Epoch: 9, Idx: 200, Training Loss: 0.5807, Training Accuracy:  62.50%\n","(train_model) Epoch: 9, Idx: 300, Training Loss: 0.4879, Training Accuracy:  81.25%\n","(train_model) Epoch: 9, Idx: 400, Training Loss: 0.6705, Training Accuracy:  62.50%\n","Epoch: 09, Train Loss: 0.425, Train Acc: 80.27%, Val. Loss: 0.417411, Val. Acc: 80.80%\n","(train_model) Epoch: 10, Idx: 100, Training Loss: 0.5316, Training Accuracy:  75.00%\n","(train_model) Epoch: 10, Idx: 200, Training Loss: 0.4938, Training Accuracy:  81.25%\n","(train_model) Epoch: 10, Idx: 300, Training Loss: 0.4487, Training Accuracy:  68.75%\n","(train_model) Epoch: 10, Idx: 400, Training Loss: 0.5812, Training Accuracy:  62.50%\n","Epoch: 10, Train Loss: 0.391, Train Acc: 82.75%, Val. Loss: 0.404560, Val. Acc: 78.64%\n","(train_model) Epoch: 11, Idx: 100, Training Loss: 0.4166, Training Accuracy:  75.00%\n","(train_model) Epoch: 11, Idx: 200, Training Loss: 0.5284, Training Accuracy:  68.75%\n","(train_model) Epoch: 11, Idx: 300, Training Loss: 0.2320, Training Accuracy:  93.75%\n","(train_model) Epoch: 11, Idx: 400, Training Loss: 0.4815, Training Accuracy:  68.75%\n","Epoch: 11, Train Loss: 0.364, Train Acc: 83.50%, Val. Loss: 0.318082, Val. Acc: 86.40%\n","(train_model) Epoch: 12, Idx: 100, Training Loss: 0.5582, Training Accuracy:  68.75%\n","(train_model) Epoch: 12, Idx: 200, Training Loss: 0.4708, Training Accuracy:  81.25%\n","(train_model) Epoch: 12, Idx: 300, Training Loss: 0.2309, Training Accuracy:  100.00%\n","(train_model) Epoch: 12, Idx: 400, Training Loss: 0.4639, Training Accuracy:  68.75%\n","Epoch: 12, Train Loss: 0.349, Train Acc: 84.67%, Val. Loss: 0.337259, Val. Acc: 85.18%\n","(train_model) Epoch: 13, Idx: 100, Training Loss: 0.4771, Training Accuracy:  81.25%\n","(train_model) Epoch: 13, Idx: 200, Training Loss: 0.3923, Training Accuracy:  87.50%\n","(train_model) Epoch: 13, Idx: 300, Training Loss: 0.3879, Training Accuracy:  87.50%\n","(train_model) Epoch: 13, Idx: 400, Training Loss: 0.5321, Training Accuracy:  75.00%\n","Epoch: 13, Train Loss: 0.325, Train Acc: 85.67%, Val. Loss: 0.368084, Val. Acc: 84.44%\n","(train_model) Epoch: 14, Idx: 100, Training Loss: 0.5488, Training Accuracy:  75.00%\n","(train_model) Epoch: 14, Idx: 200, Training Loss: 0.2886, Training Accuracy:  87.50%\n","(train_model) Epoch: 14, Idx: 300, Training Loss: 0.1656, Training Accuracy:  93.75%\n","(train_model) Epoch: 14, Idx: 400, Training Loss: 0.4940, Training Accuracy:  81.25%\n","Epoch: 14, Train Loss: 0.318, Train Acc: 86.54%, Val. Loss: 0.356086, Val. Acc: 84.58%\n","(train_model) Epoch: 15, Idx: 100, Training Loss: 0.5023, Training Accuracy:  81.25%\n","(train_model) Epoch: 15, Idx: 200, Training Loss: 0.3215, Training Accuracy:  93.75%\n","(train_model) Epoch: 15, Idx: 300, Training Loss: 0.3202, Training Accuracy:  93.75%\n","(train_model) Epoch: 15, Idx: 400, Training Loss: 0.4015, Training Accuracy:  81.25%\n","Epoch: 15, Train Loss: 0.311, Train Acc: 86.90%, Val. Loss: 0.382386, Val. Acc: 82.86%\n","(train_model) Epoch: 16, Idx: 100, Training Loss: 0.5557, Training Accuracy:  68.75%\n","(train_model) Epoch: 16, Idx: 200, Training Loss: 0.2471, Training Accuracy:  87.50%\n","(train_model) Epoch: 16, Idx: 300, Training Loss: 0.3090, Training Accuracy:  87.50%\n","(train_model) Epoch: 16, Idx: 400, Training Loss: 0.2723, Training Accuracy:  87.50%\n","Epoch: 16, Train Loss: 0.308, Train Acc: 86.77%, Val. Loss: 0.359057, Val. Acc: 84.86%\n","(train_model) Epoch: 17, Idx: 100, Training Loss: 0.6499, Training Accuracy:  68.75%\n","(train_model) Epoch: 17, Idx: 200, Training Loss: 0.2937, Training Accuracy:  93.75%\n","(train_model) Epoch: 17, Idx: 300, Training Loss: 0.1868, Training Accuracy:  100.00%\n","(train_model) Epoch: 17, Idx: 400, Training Loss: 0.3331, Training Accuracy:  87.50%\n","Epoch: 17, Train Loss: 0.299, Train Acc: 87.55%, Val. Loss: 0.370822, Val. Acc: 85.94%\n","(train_model) Epoch: 18, Idx: 100, Training Loss: 0.3722, Training Accuracy:  87.50%\n","(train_model) Epoch: 18, Idx: 200, Training Loss: 0.3594, Training Accuracy:  87.50%\n","(train_model) Epoch: 18, Idx: 300, Training Loss: 0.2821, Training Accuracy:  87.50%\n","(train_model) Epoch: 18, Idx: 400, Training Loss: 0.2687, Training Accuracy:  87.50%\n","Epoch: 18, Train Loss: 0.287, Train Acc: 87.68%, Val. Loss: 0.301351, Val. Acc: 87.88%\n","(train_model) Epoch: 19, Idx: 100, Training Loss: 0.4865, Training Accuracy:  81.25%\n","(train_model) Epoch: 19, Idx: 200, Training Loss: 0.2808, Training Accuracy:  93.75%\n","(train_model) Epoch: 19, Idx: 300, Training Loss: 0.2696, Training Accuracy:  93.75%\n","(train_model) Epoch: 19, Idx: 400, Training Loss: 0.2711, Training Accuracy:  81.25%\n","Epoch: 19, Train Loss: 0.293, Train Acc: 87.64%, Val. Loss: 0.299487, Val. Acc: 88.10%\n","(train_model) Epoch: 20, Idx: 100, Training Loss: 0.4590, Training Accuracy:  81.25%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 20, Idx: 200, Training Loss: 0.3428, Training Accuracy:  87.50%\n","(train_model) Epoch: 20, Idx: 300, Training Loss: 0.2554, Training Accuracy:  93.75%\n","(train_model) Epoch: 20, Idx: 400, Training Loss: 0.1724, Training Accuracy:  100.00%\n","Epoch: 20, Train Loss: 0.274, Train Acc: 88.76%, Val. Loss: 0.288090, Val. Acc: 88.74%\n","(train_model) Epoch: 21, Idx: 100, Training Loss: 0.4875, Training Accuracy:  81.25%\n","(train_model) Epoch: 21, Idx: 200, Training Loss: 0.4427, Training Accuracy:  87.50%\n","(train_model) Epoch: 21, Idx: 300, Training Loss: 0.1716, Training Accuracy:  93.75%\n","(train_model) Epoch: 21, Idx: 400, Training Loss: 0.2678, Training Accuracy:  81.25%\n","Epoch: 21, Train Loss: 0.269, Train Acc: 88.91%, Val. Loss: 0.297666, Val. Acc: 88.80%\n","(train_model) Epoch: 22, Idx: 100, Training Loss: 0.3115, Training Accuracy:  87.50%\n","(train_model) Epoch: 22, Idx: 200, Training Loss: 0.3057, Training Accuracy:  93.75%\n","(train_model) Epoch: 22, Idx: 300, Training Loss: 0.5228, Training Accuracy:  75.00%\n","(train_model) Epoch: 22, Idx: 400, Training Loss: 0.3331, Training Accuracy:  87.50%\n","Epoch: 22, Train Loss: 0.258, Train Acc: 89.53%, Val. Loss: 0.363012, Val. Acc: 83.98%\n","(train_model) Epoch: 23, Idx: 100, Training Loss: 0.5057, Training Accuracy:  87.50%\n","(train_model) Epoch: 23, Idx: 200, Training Loss: 0.3019, Training Accuracy:  93.75%\n","(train_model) Epoch: 23, Idx: 300, Training Loss: 0.3299, Training Accuracy:  81.25%\n","(train_model) Epoch: 23, Idx: 400, Training Loss: 0.2505, Training Accuracy:  87.50%\n","Epoch: 23, Train Loss: 0.246, Train Acc: 90.32%, Val. Loss: 0.404039, Val. Acc: 82.12%\n","(train_model) Epoch: 24, Idx: 100, Training Loss: 0.3168, Training Accuracy:  87.50%\n","(train_model) Epoch: 24, Idx: 200, Training Loss: 0.3981, Training Accuracy:  87.50%\n","(train_model) Epoch: 24, Idx: 300, Training Loss: 0.2045, Training Accuracy:  93.75%\n","(train_model) Epoch: 24, Idx: 400, Training Loss: 0.2642, Training Accuracy:  87.50%\n","Epoch: 24, Train Loss: 0.243, Train Acc: 89.99%, Val. Loss: 0.311896, Val. Acc: 85.70%\n","(train_model) Epoch: 25, Idx: 100, Training Loss: 0.1910, Training Accuracy:  93.75%\n","(train_model) Epoch: 25, Idx: 200, Training Loss: 0.3501, Training Accuracy:  93.75%\n","(train_model) Epoch: 25, Idx: 300, Training Loss: 0.0853, Training Accuracy:  100.00%\n","(train_model) Epoch: 25, Idx: 400, Training Loss: 0.2776, Training Accuracy:  87.50%\n","Epoch: 25, Train Loss: 0.238, Train Acc: 90.55%, Val. Loss: 0.284569, Val. Acc: 89.26%\n","(train_model) Epoch: 26, Idx: 100, Training Loss: 0.2292, Training Accuracy:  87.50%\n","(train_model) Epoch: 26, Idx: 200, Training Loss: 0.4004, Training Accuracy:  87.50%\n","(train_model) Epoch: 26, Idx: 300, Training Loss: 0.1709, Training Accuracy:  93.75%\n","(train_model) Epoch: 26, Idx: 400, Training Loss: 0.1213, Training Accuracy:  100.00%\n","Epoch: 26, Train Loss: 0.243, Train Acc: 90.23%, Val. Loss: 0.288921, Val. Acc: 88.94%\n","(train_model) Epoch: 27, Idx: 100, Training Loss: 0.3814, Training Accuracy:  81.25%\n","(train_model) Epoch: 27, Idx: 200, Training Loss: 0.3808, Training Accuracy:  93.75%\n","(train_model) Epoch: 27, Idx: 300, Training Loss: 0.1961, Training Accuracy:  93.75%\n","(train_model) Epoch: 27, Idx: 400, Training Loss: 0.2906, Training Accuracy:  81.25%\n","Epoch: 27, Train Loss: 0.229, Train Acc: 90.74%, Val. Loss: 0.318684, Val. Acc: 85.82%\n","(train_model) Epoch: 28, Idx: 100, Training Loss: 0.3309, Training Accuracy:  75.00%\n","(train_model) Epoch: 28, Idx: 200, Training Loss: 0.3795, Training Accuracy:  87.50%\n","(train_model) Epoch: 28, Idx: 300, Training Loss: 0.1637, Training Accuracy:  93.75%\n","(train_model) Epoch: 28, Idx: 400, Training Loss: 0.2327, Training Accuracy:  87.50%\n","Epoch: 28, Train Loss: 0.231, Train Acc: 91.02%, Val. Loss: 0.302673, Val. Acc: 88.90%\n","(train_model) Epoch: 29, Idx: 100, Training Loss: 0.1796, Training Accuracy:  93.75%\n","(train_model) Epoch: 29, Idx: 200, Training Loss: 0.2814, Training Accuracy:  93.75%\n","(train_model) Epoch: 29, Idx: 300, Training Loss: 0.1375, Training Accuracy:  93.75%\n","(train_model) Epoch: 29, Idx: 400, Training Loss: 0.3781, Training Accuracy:  75.00%\n","Epoch: 29, Train Loss: 0.240, Train Acc: 90.70%, Val. Loss: 0.289269, Val. Acc: 88.72%\n","(train_model) Epoch: 30, Idx: 100, Training Loss: 0.1401, Training Accuracy:  93.75%\n","(train_model) Epoch: 30, Idx: 200, Training Loss: 0.2776, Training Accuracy:  93.75%\n","(train_model) Epoch: 30, Idx: 300, Training Loss: 0.1425, Training Accuracy:  100.00%\n","(train_model) Epoch: 30, Idx: 400, Training Loss: 0.7396, Training Accuracy:  75.00%\n","Epoch: 30, Train Loss: 0.216, Train Acc: 91.96%, Val. Loss: 0.342999, Val. Acc: 83.98%\n","(train_model) Epoch: 31, Idx: 100, Training Loss: 0.1679, Training Accuracy:  87.50%\n","(train_model) Epoch: 31, Idx: 200, Training Loss: 0.2195, Training Accuracy:  93.75%\n","(train_model) Epoch: 31, Idx: 300, Training Loss: 0.2215, Training Accuracy:  87.50%\n","(train_model) Epoch: 31, Idx: 400, Training Loss: 0.4008, Training Accuracy:  75.00%\n","Epoch: 31, Train Loss: 0.211, Train Acc: 91.70%, Val. Loss: 0.319062, Val. Acc: 85.58%\n","(train_model) Epoch: 32, Idx: 100, Training Loss: 0.2149, Training Accuracy:  87.50%\n","(train_model) Epoch: 32, Idx: 200, Training Loss: 0.2997, Training Accuracy:  93.75%\n","(train_model) Epoch: 32, Idx: 300, Training Loss: 0.1150, Training Accuracy:  100.00%\n","(train_model) Epoch: 32, Idx: 400, Training Loss: 0.1942, Training Accuracy:  87.50%\n","Epoch: 32, Train Loss: 0.201, Train Acc: 91.79%, Val. Loss: 0.278828, Val. Acc: 87.98%\n","(train_model) Epoch: 33, Idx: 100, Training Loss: 0.2026, Training Accuracy:  87.50%\n","(train_model) Epoch: 33, Idx: 200, Training Loss: 0.1969, Training Accuracy:  93.75%\n","(train_model) Epoch: 33, Idx: 300, Training Loss: 0.1162, Training Accuracy:  100.00%\n","(train_model) Epoch: 33, Idx: 400, Training Loss: 0.2386, Training Accuracy:  87.50%\n","Epoch: 33, Train Loss: 0.197, Train Acc: 92.38%, Val. Loss: 0.322944, Val. Acc: 86.86%\n","(train_model) Epoch: 34, Idx: 100, Training Loss: 0.3398, Training Accuracy:  87.50%\n","(train_model) Epoch: 34, Idx: 200, Training Loss: 0.2588, Training Accuracy:  93.75%\n","(train_model) Epoch: 34, Idx: 300, Training Loss: 0.0985, Training Accuracy:  100.00%\n","(train_model) Epoch: 34, Idx: 400, Training Loss: 0.3396, Training Accuracy:  81.25%\n","Epoch: 34, Train Loss: 0.192, Train Acc: 92.38%, Val. Loss: 0.289160, Val. Acc: 89.12%\n","(train_model) Epoch: 35, Idx: 100, Training Loss: 0.5129, Training Accuracy:  75.00%\n","(train_model) Epoch: 35, Idx: 200, Training Loss: 0.1928, Training Accuracy:  93.75%\n","(train_model) Epoch: 35, Idx: 300, Training Loss: 0.2045, Training Accuracy:  93.75%\n","(train_model) Epoch: 35, Idx: 400, Training Loss: 0.6748, Training Accuracy:  68.75%\n","Epoch: 35, Train Loss: 0.197, Train Acc: 92.35%, Val. Loss: 0.392584, Val. Acc: 80.06%\n","(train_model) Epoch: 36, Idx: 100, Training Loss: 0.1831, Training Accuracy:  93.75%\n","(train_model) Epoch: 36, Idx: 200, Training Loss: 0.2054, Training Accuracy:  93.75%\n","(train_model) Epoch: 36, Idx: 300, Training Loss: 0.1778, Training Accuracy:  93.75%\n","(train_model) Epoch: 36, Idx: 400, Training Loss: 0.1752, Training Accuracy:  93.75%\n","Epoch: 36, Train Loss: 0.175, Train Acc: 93.28%, Val. Loss: 0.263617, Val. Acc: 90.04%\n","(train_model) Epoch: 37, Idx: 100, Training Loss: 0.2410, Training Accuracy:  87.50%\n","(train_model) Epoch: 37, Idx: 200, Training Loss: 0.4516, Training Accuracy:  93.75%\n","(train_model) Epoch: 37, Idx: 300, Training Loss: 0.1358, Training Accuracy:  93.75%\n","(train_model) Epoch: 37, Idx: 400, Training Loss: 0.1718, Training Accuracy:  93.75%\n","Epoch: 37, Train Loss: 0.181, Train Acc: 92.86%, Val. Loss: 0.309799, Val. Acc: 87.06%\n","(train_model) Epoch: 38, Idx: 100, Training Loss: 0.3834, Training Accuracy:  87.50%\n","(train_model) Epoch: 38, Idx: 200, Training Loss: 0.2233, Training Accuracy:  93.75%\n","(train_model) Epoch: 38, Idx: 300, Training Loss: 0.2683, Training Accuracy:  87.50%\n","(train_model) Epoch: 38, Idx: 400, Training Loss: 0.2254, Training Accuracy:  93.75%\n","Epoch: 38, Train Loss: 0.170, Train Acc: 93.65%, Val. Loss: 0.359328, Val. Acc: 84.84%\n","(train_model) Epoch: 39, Idx: 100, Training Loss: 0.2695, Training Accuracy:  87.50%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 39, Idx: 200, Training Loss: 0.1323, Training Accuracy:  93.75%\n","(train_model) Epoch: 39, Idx: 300, Training Loss: 0.0980, Training Accuracy:  93.75%\n","(train_model) Epoch: 39, Idx: 400, Training Loss: 0.3081, Training Accuracy:  81.25%\n","Epoch: 39, Train Loss: 0.164, Train Acc: 93.87%, Val. Loss: 0.294791, Val. Acc: 87.36%\n","(train_model) Epoch: 40, Idx: 100, Training Loss: 0.3362, Training Accuracy:  87.50%\n","(train_model) Epoch: 40, Idx: 200, Training Loss: 0.1333, Training Accuracy:  93.75%\n","(train_model) Epoch: 40, Idx: 300, Training Loss: 0.1415, Training Accuracy:  100.00%\n","(train_model) Epoch: 40, Idx: 400, Training Loss: 0.2213, Training Accuracy:  87.50%\n","Epoch: 40, Train Loss: 0.163, Train Acc: 93.75%, Val. Loss: 0.303861, Val. Acc: 89.04%\n","(train_model) Epoch: 41, Idx: 100, Training Loss: 0.6933, Training Accuracy:  50.00%\n","(train_model) Epoch: 41, Idx: 200, Training Loss: 0.7055, Training Accuracy:  37.50%\n","(train_model) Epoch: 41, Idx: 300, Training Loss: 0.8298, Training Accuracy:  37.50%\n","(train_model) Epoch: 41, Idx: 400, Training Loss: 0.6792, Training Accuracy:  56.25%\n","Epoch: 41, Train Loss: 0.690, Train Acc: 53.32%, Val. Loss: 0.694068, Val. Acc: 47.98%\n","(train_model) Epoch: 42, Idx: 100, Training Loss: 0.2983, Training Accuracy:  93.75%\n","(train_model) Epoch: 42, Idx: 200, Training Loss: 0.2179, Training Accuracy:  93.75%\n","(train_model) Epoch: 42, Idx: 300, Training Loss: 0.2033, Training Accuracy:  93.75%\n","(train_model) Epoch: 42, Idx: 400, Training Loss: 0.1308, Training Accuracy:  100.00%\n","Epoch: 42, Train Loss: 0.232, Train Acc: 91.52%, Val. Loss: 0.292283, Val. Acc: 87.84%\n","(train_model) Epoch: 43, Idx: 100, Training Loss: 0.1549, Training Accuracy:  93.75%\n","(train_model) Epoch: 43, Idx: 200, Training Loss: 0.3396, Training Accuracy:  87.50%\n","(train_model) Epoch: 43, Idx: 300, Training Loss: 0.0329, Training Accuracy:  100.00%\n","(train_model) Epoch: 43, Idx: 400, Training Loss: 0.6196, Training Accuracy:  81.25%\n","Epoch: 43, Train Loss: 0.328, Train Acc: 86.76%, Val. Loss: 0.343613, Val. Acc: 87.48%\n","(train_model) Epoch: 44, Idx: 100, Training Loss: 0.3640, Training Accuracy:  87.50%\n","(train_model) Epoch: 44, Idx: 200, Training Loss: 0.1871, Training Accuracy:  93.75%\n","(train_model) Epoch: 44, Idx: 300, Training Loss: 0.4665, Training Accuracy:  93.75%\n","(train_model) Epoch: 44, Idx: 400, Training Loss: 0.0868, Training Accuracy:  100.00%\n","Epoch: 44, Train Loss: 0.277, Train Acc: 90.45%, Val. Loss: 0.327778, Val. Acc: 86.70%\n","(train_model) Epoch: 45, Idx: 100, Training Loss: 0.3763, Training Accuracy:  87.50%\n","(train_model) Epoch: 45, Idx: 200, Training Loss: 0.0468, Training Accuracy:  100.00%\n","(train_model) Epoch: 45, Idx: 300, Training Loss: 0.0544, Training Accuracy:  100.00%\n","(train_model) Epoch: 45, Idx: 400, Training Loss: 0.1842, Training Accuracy:  87.50%\n","Epoch: 45, Train Loss: 0.224, Train Acc: 91.83%, Val. Loss: 0.327051, Val. Acc: 84.60%\n","(train_model) Epoch: 46, Idx: 100, Training Loss: 0.2151, Training Accuracy:  87.50%\n","(train_model) Epoch: 46, Idx: 200, Training Loss: 0.2055, Training Accuracy:  93.75%\n","(train_model) Epoch: 46, Idx: 300, Training Loss: 0.2690, Training Accuracy:  87.50%\n","(train_model) Epoch: 46, Idx: 400, Training Loss: 0.2598, Training Accuracy:  87.50%\n","Epoch: 46, Train Loss: 0.211, Train Acc: 92.43%, Val. Loss: 0.276035, Val. Acc: 88.96%\n","(train_model) Epoch: 47, Idx: 100, Training Loss: 0.5216, Training Accuracy:  68.75%\n","(train_model) Epoch: 47, Idx: 200, Training Loss: 0.1984, Training Accuracy:  93.75%\n","(train_model) Epoch: 47, Idx: 300, Training Loss: 0.2003, Training Accuracy:  87.50%\n","(train_model) Epoch: 47, Idx: 400, Training Loss: 0.3182, Training Accuracy:  93.75%\n","Epoch: 47, Train Loss: 0.203, Train Acc: 92.14%, Val. Loss: 0.291443, Val. Acc: 88.20%\n","(train_model) Epoch: 48, Idx: 100, Training Loss: 0.2132, Training Accuracy:  93.75%\n","(train_model) Epoch: 48, Idx: 200, Training Loss: 0.1671, Training Accuracy:  93.75%\n","(train_model) Epoch: 48, Idx: 300, Training Loss: 0.2008, Training Accuracy:  87.50%\n","(train_model) Epoch: 48, Idx: 400, Training Loss: 0.1453, Training Accuracy:  93.75%\n","Epoch: 48, Train Loss: 0.163, Train Acc: 94.09%, Val. Loss: 0.276258, Val. Acc: 89.32%\n","(train_model) Epoch: 49, Idx: 100, Training Loss: 0.0699, Training Accuracy:  100.00%\n","(train_model) Epoch: 49, Idx: 200, Training Loss: 0.2103, Training Accuracy:  93.75%\n","(train_model) Epoch: 49, Idx: 300, Training Loss: 0.1001, Training Accuracy:  100.00%\n","(train_model) Epoch: 49, Idx: 400, Training Loss: 0.1406, Training Accuracy:  100.00%\n","Epoch: 49, Train Loss: 0.159, Train Acc: 94.24%, Val. Loss: 0.258140, Val. Acc: 89.16%\n","(train_model) Epoch: 50, Idx: 100, Training Loss: 0.5992, Training Accuracy:  81.25%\n","(train_model) Epoch: 50, Idx: 200, Training Loss: 0.1258, Training Accuracy:  93.75%\n","(train_model) Epoch: 50, Idx: 300, Training Loss: 0.0697, Training Accuracy:  100.00%\n","(train_model) Epoch: 50, Idx: 400, Training Loss: 0.2329, Training Accuracy:  81.25%\n","Epoch: 50, Train Loss: 0.167, Train Acc: 93.74%, Val. Loss: 0.329419, Val. Acc: 87.32%\n","(train_model) Epoch: 51, Idx: 100, Training Loss: 0.2088, Training Accuracy:  93.75%\n","(train_model) Epoch: 51, Idx: 200, Training Loss: 0.3366, Training Accuracy:  93.75%\n","(train_model) Epoch: 51, Idx: 300, Training Loss: 0.2293, Training Accuracy:  93.75%\n","(train_model) Epoch: 51, Idx: 400, Training Loss: 0.2438, Training Accuracy:  93.75%\n","Epoch: 51, Train Loss: 0.166, Train Acc: 93.90%, Val. Loss: 0.287720, Val. Acc: 88.52%\n","(train_model) Epoch: 52, Idx: 100, Training Loss: 0.2121, Training Accuracy:  93.75%\n","(train_model) Epoch: 52, Idx: 200, Training Loss: 0.4067, Training Accuracy:  87.50%\n","(train_model) Epoch: 52, Idx: 300, Training Loss: 0.1238, Training Accuracy:  93.75%\n","(train_model) Epoch: 52, Idx: 400, Training Loss: 0.1529, Training Accuracy:  93.75%\n","Epoch: 52, Train Loss: 0.148, Train Acc: 94.59%, Val. Loss: 0.346122, Val. Acc: 84.80%\n","(train_model) Epoch: 53, Idx: 100, Training Loss: 0.6827, Training Accuracy:  81.25%\n","(train_model) Epoch: 53, Idx: 200, Training Loss: 0.1657, Training Accuracy:  93.75%\n","(train_model) Epoch: 53, Idx: 300, Training Loss: 0.0332, Training Accuracy:  100.00%\n","(train_model) Epoch: 53, Idx: 400, Training Loss: 0.1038, Training Accuracy:  93.75%\n","Epoch: 53, Train Loss: 0.150, Train Acc: 94.45%, Val. Loss: 0.286953, Val. Acc: 88.58%\n","(train_model) Epoch: 54, Idx: 100, Training Loss: 0.4108, Training Accuracy:  87.50%\n","(train_model) Epoch: 54, Idx: 200, Training Loss: 0.0913, Training Accuracy:  93.75%\n","(train_model) Epoch: 54, Idx: 300, Training Loss: 0.0706, Training Accuracy:  93.75%\n","(train_model) Epoch: 54, Idx: 400, Training Loss: 0.1968, Training Accuracy:  87.50%\n","Epoch: 54, Train Loss: 0.140, Train Acc: 95.16%, Val. Loss: 0.335319, Val. Acc: 86.02%\n","(train_model) Epoch: 55, Idx: 100, Training Loss: 0.2704, Training Accuracy:  87.50%\n","(train_model) Epoch: 55, Idx: 200, Training Loss: 0.0897, Training Accuracy:  100.00%\n","(train_model) Epoch: 55, Idx: 300, Training Loss: 0.0255, Training Accuracy:  100.00%\n","(train_model) Epoch: 55, Idx: 400, Training Loss: 0.4633, Training Accuracy:  87.50%\n","Epoch: 55, Train Loss: 0.156, Train Acc: 94.75%, Val. Loss: 0.322339, Val. Acc: 87.68%\n","(train_model) Epoch: 56, Idx: 100, Training Loss: 0.1980, Training Accuracy:  81.25%\n","(train_model) Epoch: 56, Idx: 200, Training Loss: 0.3112, Training Accuracy:  93.75%\n","(train_model) Epoch: 56, Idx: 300, Training Loss: 0.0748, Training Accuracy:  100.00%\n","(train_model) Epoch: 56, Idx: 400, Training Loss: 0.1822, Training Accuracy:  93.75%\n","Epoch: 56, Train Loss: 0.159, Train Acc: 94.07%, Val. Loss: 0.269331, Val. Acc: 89.78%\n","(train_model) Epoch: 57, Idx: 100, Training Loss: 0.6255, Training Accuracy:  75.00%\n","(train_model) Epoch: 57, Idx: 200, Training Loss: 0.3371, Training Accuracy:  93.75%\n","(train_model) Epoch: 57, Idx: 300, Training Loss: 0.0568, Training Accuracy:  100.00%\n","(train_model) Epoch: 57, Idx: 400, Training Loss: 0.0631, Training Accuracy:  100.00%\n","Epoch: 57, Train Loss: 0.140, Train Acc: 94.78%, Val. Loss: 0.283199, Val. Acc: 89.44%\n","(train_model) Epoch: 58, Idx: 100, Training Loss: 0.3970, Training Accuracy:  93.75%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 58, Idx: 200, Training Loss: 0.1083, Training Accuracy:  100.00%\n","(train_model) Epoch: 58, Idx: 300, Training Loss: 0.4267, Training Accuracy:  87.50%\n","(train_model) Epoch: 58, Idx: 400, Training Loss: 0.0974, Training Accuracy:  100.00%\n","Epoch: 58, Train Loss: 0.151, Train Acc: 94.74%, Val. Loss: 0.266154, Val. Acc: 89.18%\n","(train_model) Epoch: 59, Idx: 100, Training Loss: 0.5972, Training Accuracy:  75.00%\n","(train_model) Epoch: 59, Idx: 200, Training Loss: 0.1224, Training Accuracy:  93.75%\n","(train_model) Epoch: 59, Idx: 300, Training Loss: 0.1152, Training Accuracy:  100.00%\n","(train_model) Epoch: 59, Idx: 400, Training Loss: 0.0567, Training Accuracy:  100.00%\n","Epoch: 59, Train Loss: 0.142, Train Acc: 94.60%, Val. Loss: 0.436353, Val. Acc: 80.60%\n","(train_model) Epoch: 60, Idx: 100, Training Loss: 0.2620, Training Accuracy:  87.50%\n","(train_model) Epoch: 60, Idx: 200, Training Loss: 0.1498, Training Accuracy:  93.75%\n","(train_model) Epoch: 60, Idx: 300, Training Loss: 0.0401, Training Accuracy:  100.00%\n","(train_model) Epoch: 60, Idx: 400, Training Loss: 0.2298, Training Accuracy:  87.50%\n","Epoch: 60, Train Loss: 0.131, Train Acc: 95.15%, Val. Loss: 0.279991, Val. Acc: 89.28%\n","(train_model) Epoch: 61, Idx: 100, Training Loss: 0.1480, Training Accuracy:  93.75%\n","(train_model) Epoch: 61, Idx: 200, Training Loss: 0.2974, Training Accuracy:  87.50%\n","(train_model) Epoch: 61, Idx: 300, Training Loss: 0.0285, Training Accuracy:  100.00%\n","(train_model) Epoch: 61, Idx: 400, Training Loss: 0.1170, Training Accuracy:  93.75%\n","Epoch: 61, Train Loss: 0.135, Train Acc: 95.22%, Val. Loss: 0.283717, Val. Acc: 89.06%\n","(train_model) Epoch: 62, Idx: 100, Training Loss: 0.0735, Training Accuracy:  100.00%\n","(train_model) Epoch: 62, Idx: 200, Training Loss: 0.1151, Training Accuracy:  93.75%\n","(train_model) Epoch: 62, Idx: 300, Training Loss: 0.0272, Training Accuracy:  100.00%\n","(train_model) Epoch: 62, Idx: 400, Training Loss: 0.0661, Training Accuracy:  100.00%\n","Epoch: 62, Train Loss: 0.121, Train Acc: 95.38%, Val. Loss: 0.299306, Val. Acc: 87.96%\n","(train_model) Epoch: 63, Idx: 100, Training Loss: 0.2228, Training Accuracy:  87.50%\n","(train_model) Epoch: 63, Idx: 200, Training Loss: 0.0826, Training Accuracy:  93.75%\n","(train_model) Epoch: 63, Idx: 300, Training Loss: 0.0134, Training Accuracy:  100.00%\n","(train_model) Epoch: 63, Idx: 400, Training Loss: 0.0833, Training Accuracy:  93.75%\n","Epoch: 63, Train Loss: 0.120, Train Acc: 95.52%, Val. Loss: 0.295293, Val. Acc: 87.54%\n","(train_model) Epoch: 64, Idx: 100, Training Loss: 0.0251, Training Accuracy:  100.00%\n","(train_model) Epoch: 64, Idx: 200, Training Loss: 0.3915, Training Accuracy:  87.50%\n","(train_model) Epoch: 64, Idx: 300, Training Loss: 0.0702, Training Accuracy:  100.00%\n","(train_model) Epoch: 64, Idx: 400, Training Loss: 0.1267, Training Accuracy:  93.75%\n","Epoch: 64, Train Loss: 0.107, Train Acc: 96.00%, Val. Loss: 0.268576, Val. Acc: 89.38%\n","(train_model) Epoch: 65, Idx: 100, Training Loss: 0.5547, Training Accuracy:  81.25%\n","(train_model) Epoch: 65, Idx: 200, Training Loss: 0.1209, Training Accuracy:  87.50%\n","(train_model) Epoch: 65, Idx: 300, Training Loss: 0.1090, Training Accuracy:  100.00%\n","(train_model) Epoch: 65, Idx: 400, Training Loss: 0.0177, Training Accuracy:  100.00%\n","Epoch: 65, Train Loss: 0.117, Train Acc: 95.95%, Val. Loss: 0.279602, Val. Acc: 88.92%\n","(train_model) Epoch: 66, Idx: 100, Training Loss: 0.1310, Training Accuracy:  87.50%\n","(train_model) Epoch: 66, Idx: 200, Training Loss: 0.0378, Training Accuracy:  100.00%\n","(train_model) Epoch: 66, Idx: 300, Training Loss: 0.1529, Training Accuracy:  93.75%\n","(train_model) Epoch: 66, Idx: 400, Training Loss: 0.1625, Training Accuracy:  93.75%\n","Epoch: 66, Train Loss: 0.104, Train Acc: 96.35%, Val. Loss: 0.305306, Val. Acc: 88.08%\n","(train_model) Epoch: 67, Idx: 100, Training Loss: 0.1047, Training Accuracy:  93.75%\n","(train_model) Epoch: 67, Idx: 200, Training Loss: 0.2217, Training Accuracy:  93.75%\n","(train_model) Epoch: 67, Idx: 300, Training Loss: 0.0857, Training Accuracy:  100.00%\n","(train_model) Epoch: 67, Idx: 400, Training Loss: 0.0362, Training Accuracy:  100.00%\n","Epoch: 67, Train Loss: 0.102, Train Acc: 96.36%, Val. Loss: 0.307110, Val. Acc: 87.96%\n","(train_model) Epoch: 68, Idx: 100, Training Loss: 0.2158, Training Accuracy:  87.50%\n","(train_model) Epoch: 68, Idx: 200, Training Loss: 0.1132, Training Accuracy:  93.75%\n","(train_model) Epoch: 68, Idx: 300, Training Loss: 0.0562, Training Accuracy:  100.00%\n","(train_model) Epoch: 68, Idx: 400, Training Loss: 0.0524, Training Accuracy:  100.00%\n","Epoch: 68, Train Loss: 0.102, Train Acc: 96.22%, Val. Loss: 0.293179, Val. Acc: 87.84%\n","(train_model) Epoch: 69, Idx: 100, Training Loss: 0.2388, Training Accuracy:  87.50%\n","(train_model) Epoch: 69, Idx: 200, Training Loss: 0.0262, Training Accuracy:  100.00%\n","(train_model) Epoch: 69, Idx: 300, Training Loss: 0.0314, Training Accuracy:  100.00%\n","(train_model) Epoch: 69, Idx: 400, Training Loss: 0.0064, Training Accuracy:  100.00%\n","Epoch: 69, Train Loss: 0.099, Train Acc: 96.43%, Val. Loss: 0.287067, Val. Acc: 87.30%\n","(train_model) Epoch: 70, Idx: 100, Training Loss: 0.0549, Training Accuracy:  100.00%\n","(train_model) Epoch: 70, Idx: 200, Training Loss: 0.2064, Training Accuracy:  93.75%\n","(train_model) Epoch: 70, Idx: 300, Training Loss: 0.0290, Training Accuracy:  100.00%\n","(train_model) Epoch: 70, Idx: 400, Training Loss: 0.0111, Training Accuracy:  100.00%\n","Epoch: 70, Train Loss: 0.099, Train Acc: 96.50%, Val. Loss: 0.278988, Val. Acc: 88.08%\n","(train_model) Epoch: 71, Idx: 100, Training Loss: 0.0482, Training Accuracy:  100.00%\n","(train_model) Epoch: 71, Idx: 200, Training Loss: 0.2511, Training Accuracy:  93.75%\n","(train_model) Epoch: 71, Idx: 300, Training Loss: 0.0731, Training Accuracy:  100.00%\n","(train_model) Epoch: 71, Idx: 400, Training Loss: 0.0987, Training Accuracy:  93.75%\n","Epoch: 71, Train Loss: 0.103, Train Acc: 96.25%, Val. Loss: 0.294394, Val. Acc: 87.30%\n","(train_model) Epoch: 72, Idx: 100, Training Loss: 0.1232, Training Accuracy:  93.75%\n","(train_model) Epoch: 72, Idx: 200, Training Loss: 0.0267, Training Accuracy:  100.00%\n","(train_model) Epoch: 72, Idx: 300, Training Loss: 0.0878, Training Accuracy:  93.75%\n","(train_model) Epoch: 72, Idx: 400, Training Loss: 0.0452, Training Accuracy:  100.00%\n","Epoch: 72, Train Loss: 0.092, Train Acc: 96.62%, Val. Loss: 0.248383, Val. Acc: 89.88%\n","(train_model) Epoch: 73, Idx: 100, Training Loss: 0.2950, Training Accuracy:  87.50%\n","(train_model) Epoch: 73, Idx: 200, Training Loss: 0.0450, Training Accuracy:  100.00%\n","(train_model) Epoch: 73, Idx: 300, Training Loss: 0.1710, Training Accuracy:  87.50%\n","(train_model) Epoch: 73, Idx: 400, Training Loss: 0.0488, Training Accuracy:  100.00%\n","Epoch: 73, Train Loss: 0.085, Train Acc: 97.07%, Val. Loss: 0.269985, Val. Acc: 89.46%\n","(train_model) Epoch: 74, Idx: 100, Training Loss: 0.2371, Training Accuracy:  87.50%\n","(train_model) Epoch: 74, Idx: 200, Training Loss: 0.0057, Training Accuracy:  100.00%\n","(train_model) Epoch: 74, Idx: 300, Training Loss: 0.0182, Training Accuracy:  100.00%\n","(train_model) Epoch: 74, Idx: 400, Training Loss: 0.0570, Training Accuracy:  100.00%\n","Epoch: 74, Train Loss: 0.097, Train Acc: 96.85%, Val. Loss: 0.289473, Val. Acc: 88.32%\n","(train_model) Epoch: 75, Idx: 100, Training Loss: 0.1442, Training Accuracy:  93.75%\n","(train_model) Epoch: 75, Idx: 200, Training Loss: 0.0590, Training Accuracy:  93.75%\n","(train_model) Epoch: 75, Idx: 300, Training Loss: 0.0333, Training Accuracy:  100.00%\n","(train_model) Epoch: 75, Idx: 400, Training Loss: 0.0673, Training Accuracy:  93.75%\n","Epoch: 75, Train Loss: 0.092, Train Acc: 96.85%, Val. Loss: 0.312666, Val. Acc: 86.64%\n","(train_model) Epoch: 76, Idx: 100, Training Loss: 0.1468, Training Accuracy:  93.75%\n","(train_model) Epoch: 76, Idx: 200, Training Loss: 0.0791, Training Accuracy:  93.75%\n","(train_model) Epoch: 76, Idx: 300, Training Loss: 0.2139, Training Accuracy:  87.50%\n","(train_model) Epoch: 76, Idx: 400, Training Loss: 0.0065, Training Accuracy:  100.00%\n","Epoch: 76, Train Loss: 0.091, Train Acc: 96.92%, Val. Loss: 0.332055, Val. Acc: 86.16%\n","(train_model) Epoch: 77, Idx: 100, Training Loss: 0.0720, Training Accuracy:  93.75%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 77, Idx: 200, Training Loss: 0.0196, Training Accuracy:  100.00%\n","(train_model) Epoch: 77, Idx: 300, Training Loss: 0.0584, Training Accuracy:  93.75%\n","(train_model) Epoch: 77, Idx: 400, Training Loss: 0.0508, Training Accuracy:  100.00%\n","Epoch: 77, Train Loss: 0.087, Train Acc: 96.87%, Val. Loss: 0.284407, Val. Acc: 88.24%\n","(train_model) Epoch: 78, Idx: 100, Training Loss: 0.0279, Training Accuracy:  100.00%\n","(train_model) Epoch: 78, Idx: 200, Training Loss: 0.0076, Training Accuracy:  100.00%\n","(train_model) Epoch: 78, Idx: 300, Training Loss: 0.0068, Training Accuracy:  100.00%\n","(train_model) Epoch: 78, Idx: 400, Training Loss: 0.0139, Training Accuracy:  100.00%\n","Epoch: 78, Train Loss: 0.080, Train Acc: 97.53%, Val. Loss: 0.346305, Val. Acc: 83.30%\n","(train_model) Epoch: 79, Idx: 100, Training Loss: 0.0786, Training Accuracy:  100.00%\n","(train_model) Epoch: 79, Idx: 200, Training Loss: 0.0179, Training Accuracy:  100.00%\n","(train_model) Epoch: 79, Idx: 300, Training Loss: 0.0168, Training Accuracy:  100.00%\n","(train_model) Epoch: 79, Idx: 400, Training Loss: 0.0138, Training Accuracy:  100.00%\n","Epoch: 79, Train Loss: 0.085, Train Acc: 97.05%, Val. Loss: 0.249912, Val. Acc: 90.70%\n","(train_model) Epoch: 80, Idx: 100, Training Loss: 0.0110, Training Accuracy:  100.00%\n","(train_model) Epoch: 80, Idx: 200, Training Loss: 0.0135, Training Accuracy:  100.00%\n","(train_model) Epoch: 80, Idx: 300, Training Loss: 0.0237, Training Accuracy:  100.00%\n","(train_model) Epoch: 80, Idx: 400, Training Loss: 0.0703, Training Accuracy:  93.75%\n","Epoch: 80, Train Loss: 0.081, Train Acc: 97.27%, Val. Loss: 0.306105, Val. Acc: 87.94%\n","(train_model) Epoch: 81, Idx: 100, Training Loss: 0.1810, Training Accuracy:  87.50%\n","(train_model) Epoch: 81, Idx: 200, Training Loss: 0.0744, Training Accuracy:  93.75%\n","(train_model) Epoch: 81, Idx: 300, Training Loss: 0.0585, Training Accuracy:  100.00%\n","(train_model) Epoch: 81, Idx: 400, Training Loss: 0.0581, Training Accuracy:  93.75%\n","Epoch: 81, Train Loss: 0.082, Train Acc: 97.12%, Val. Loss: 0.301223, Val. Acc: 86.32%\n","(train_model) Epoch: 82, Idx: 100, Training Loss: 0.1516, Training Accuracy:  87.50%\n","(train_model) Epoch: 82, Idx: 200, Training Loss: 0.1442, Training Accuracy:  93.75%\n","(train_model) Epoch: 82, Idx: 300, Training Loss: 0.0759, Training Accuracy:  93.75%\n","(train_model) Epoch: 82, Idx: 400, Training Loss: 0.0088, Training Accuracy:  100.00%\n","Epoch: 82, Train Loss: 0.074, Train Acc: 97.39%, Val. Loss: 0.291402, Val. Acc: 88.30%\n","(train_model) Epoch: 83, Idx: 100, Training Loss: 0.1717, Training Accuracy:  93.75%\n","(train_model) Epoch: 83, Idx: 200, Training Loss: 0.0365, Training Accuracy:  100.00%\n","(train_model) Epoch: 83, Idx: 300, Training Loss: 0.0131, Training Accuracy:  100.00%\n","(train_model) Epoch: 83, Idx: 400, Training Loss: 0.0088, Training Accuracy:  100.00%\n","Epoch: 83, Train Loss: 0.075, Train Acc: 97.45%, Val. Loss: 0.332235, Val. Acc: 86.84%\n","(train_model) Epoch: 84, Idx: 100, Training Loss: 0.3601, Training Accuracy:  75.00%\n","(train_model) Epoch: 84, Idx: 200, Training Loss: 0.0496, Training Accuracy:  100.00%\n","(train_model) Epoch: 84, Idx: 300, Training Loss: 0.0088, Training Accuracy:  100.00%\n","(train_model) Epoch: 84, Idx: 400, Training Loss: 0.0166, Training Accuracy:  100.00%\n","Epoch: 84, Train Loss: 0.077, Train Acc: 97.28%, Val. Loss: 0.273612, Val. Acc: 89.56%\n","(train_model) Epoch: 85, Idx: 100, Training Loss: 0.0261, Training Accuracy:  100.00%\n","(train_model) Epoch: 85, Idx: 200, Training Loss: 0.0277, Training Accuracy:  100.00%\n","(train_model) Epoch: 85, Idx: 300, Training Loss: 0.0047, Training Accuracy:  100.00%\n","(train_model) Epoch: 85, Idx: 400, Training Loss: 0.0100, Training Accuracy:  100.00%\n","Epoch: 85, Train Loss: 0.075, Train Acc: 97.23%, Val. Loss: 0.270920, Val. Acc: 89.94%\n","(train_model) Epoch: 86, Idx: 100, Training Loss: 0.0889, Training Accuracy:  93.75%\n","(train_model) Epoch: 86, Idx: 200, Training Loss: 0.0013, Training Accuracy:  100.00%\n","(train_model) Epoch: 86, Idx: 300, Training Loss: 0.0158, Training Accuracy:  100.00%\n","(train_model) Epoch: 86, Idx: 400, Training Loss: 0.0114, Training Accuracy:  100.00%\n","Epoch: 86, Train Loss: 0.074, Train Acc: 97.60%, Val. Loss: 0.337499, Val. Acc: 86.60%\n","(train_model) Epoch: 87, Idx: 100, Training Loss: 0.3942, Training Accuracy:  93.75%\n","(train_model) Epoch: 87, Idx: 200, Training Loss: 0.0622, Training Accuracy:  100.00%\n","(train_model) Epoch: 87, Idx: 300, Training Loss: 0.0239, Training Accuracy:  100.00%\n","(train_model) Epoch: 87, Idx: 400, Training Loss: 0.0998, Training Accuracy:  93.75%\n","Epoch: 87, Train Loss: 0.075, Train Acc: 97.57%, Val. Loss: 0.272921, Val. Acc: 90.02%\n","(train_model) Epoch: 88, Idx: 100, Training Loss: 0.0406, Training Accuracy:  100.00%\n","(train_model) Epoch: 88, Idx: 200, Training Loss: 0.0268, Training Accuracy:  100.00%\n","(train_model) Epoch: 88, Idx: 300, Training Loss: 0.0508, Training Accuracy:  100.00%\n","(train_model) Epoch: 88, Idx: 400, Training Loss: 0.1057, Training Accuracy:  93.75%\n","Epoch: 88, Train Loss: 0.070, Train Acc: 97.64%, Val. Loss: 0.286735, Val. Acc: 87.94%\n","(train_model) Epoch: 89, Idx: 100, Training Loss: 0.2125, Training Accuracy:  87.50%\n","(train_model) Epoch: 89, Idx: 200, Training Loss: 0.0043, Training Accuracy:  100.00%\n","(train_model) Epoch: 89, Idx: 300, Training Loss: 0.0356, Training Accuracy:  100.00%\n","(train_model) Epoch: 89, Idx: 400, Training Loss: 0.0048, Training Accuracy:  100.00%\n","Epoch: 89, Train Loss: 0.067, Train Acc: 97.45%, Val. Loss: 0.329389, Val. Acc: 85.60%\n","(train_model) Epoch: 90, Idx: 100, Training Loss: 0.0481, Training Accuracy:  100.00%\n","(train_model) Epoch: 90, Idx: 200, Training Loss: 0.0247, Training Accuracy:  100.00%\n","(train_model) Epoch: 90, Idx: 300, Training Loss: 0.0076, Training Accuracy:  100.00%\n","(train_model) Epoch: 90, Idx: 400, Training Loss: 0.0051, Training Accuracy:  100.00%\n","Epoch: 90, Train Loss: 0.070, Train Acc: 97.54%, Val. Loss: 0.308895, Val. Acc: 86.26%\n","(train_model) Epoch: 91, Idx: 100, Training Loss: 0.1546, Training Accuracy:  93.75%\n","(train_model) Epoch: 91, Idx: 200, Training Loss: 0.0270, Training Accuracy:  100.00%\n","(train_model) Epoch: 91, Idx: 300, Training Loss: 0.0041, Training Accuracy:  100.00%\n","(train_model) Epoch: 91, Idx: 400, Training Loss: 0.2514, Training Accuracy:  87.50%\n","Epoch: 91, Train Loss: 0.065, Train Acc: 97.86%, Val. Loss: 0.284214, Val. Acc: 87.94%\n","(train_model) Epoch: 92, Idx: 100, Training Loss: 0.0026, Training Accuracy:  100.00%\n","(train_model) Epoch: 92, Idx: 200, Training Loss: 0.1016, Training Accuracy:  93.75%\n","(train_model) Epoch: 92, Idx: 300, Training Loss: 0.0030, Training Accuracy:  100.00%\n","(train_model) Epoch: 92, Idx: 400, Training Loss: 0.0009, Training Accuracy:  100.00%\n","Epoch: 92, Train Loss: 0.068, Train Acc: 97.69%, Val. Loss: 0.354279, Val. Acc: 89.12%\n","(train_model) Epoch: 93, Idx: 100, Training Loss: 0.0372, Training Accuracy:  100.00%\n","(train_model) Epoch: 93, Idx: 200, Training Loss: 0.0208, Training Accuracy:  100.00%\n","(train_model) Epoch: 93, Idx: 300, Training Loss: 0.0358, Training Accuracy:  100.00%\n","(train_model) Epoch: 93, Idx: 400, Training Loss: 0.0140, Training Accuracy:  100.00%\n","Epoch: 93, Train Loss: 0.077, Train Acc: 97.86%, Val. Loss: 0.287800, Val. Acc: 89.20%\n","(train_model) Epoch: 94, Idx: 100, Training Loss: 0.0288, Training Accuracy:  100.00%\n","(train_model) Epoch: 94, Idx: 200, Training Loss: 0.0093, Training Accuracy:  100.00%\n","(train_model) Epoch: 94, Idx: 300, Training Loss: 0.0408, Training Accuracy:  100.00%\n","(train_model) Epoch: 94, Idx: 400, Training Loss: 0.0140, Training Accuracy:  100.00%\n","Epoch: 94, Train Loss: 0.068, Train Acc: 97.87%, Val. Loss: 0.270622, Val. Acc: 89.76%\n","(train_model) Epoch: 95, Idx: 100, Training Loss: 0.0204, Training Accuracy:  100.00%\n","(train_model) Epoch: 95, Idx: 200, Training Loss: 0.0274, Training Accuracy:  100.00%\n","(train_model) Epoch: 95, Idx: 300, Training Loss: 0.1830, Training Accuracy:  93.75%\n","(train_model) Epoch: 95, Idx: 400, Training Loss: 0.0079, Training Accuracy:  100.00%\n","Epoch: 95, Train Loss: 0.075, Train Acc: 97.34%, Val. Loss: 0.273969, Val. Acc: 88.66%\n","(train_model) Epoch: 96, Idx: 100, Training Loss: 0.0028, Training Accuracy:  100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["(train_model) Epoch: 96, Idx: 200, Training Loss: 0.0301, Training Accuracy:  100.00%\n","(train_model) Epoch: 96, Idx: 300, Training Loss: 0.0032, Training Accuracy:  100.00%\n","(train_model) Epoch: 96, Idx: 400, Training Loss: 0.0104, Training Accuracy:  100.00%\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-23-b8661be02346>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_acc_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mval_acc_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-11-89c062eeaa02>\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(model, val_iter)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mnum_corrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-10-f58b70f7ce86>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_sentence, batch_size)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m       \u001b[0mh_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Initial hidden state of the LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m       \u001b[0mc_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Initial cell state of the LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Gd8OMuJ6gVio","colab_type":"code","colab":{},"outputId":"4efeda2b-e76c-4779-8621-aaae8ef0db93"},"source":["print(f'Best train acc: {max(train_acc_history):.2f}%, best val acc: {max(val_acc_history):.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Best train acc: 97.87%, best val acc: 90.70%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Jgm6vVn1PZtc","colab":{}},"source":["# test_loss, test_acc = eval_model(model, test_iter)\n","# print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z7EugnSPPZte","colab":{}},"source":["# ''' Let us now predict on a single sentence just for the testing purpose. '''\n","# test_sen1 = \"This is one of the best creation of Nolan. I can say, it's his magnum opus. Loved the soundtrack and especially those creative dialogues.\"\n","# test_sen2 = \"Ohh, such a ridiculous movie. Not gonna recommend it to anyone. Complete waste of time and money.\"\n","\n","# # format sentence into a 1 x max_seq_len tokenized and padded np array, then convert to tensor\n","# # test_sen1 = ...\n","\n","# test_sen = np.asarray(test_sen1)\n","# test_sen = torch.LongTensor(test_sen)\n","\n","# test_tensor = Variable(test_sen, volatile=True)\n","# test_tensor = test_tensor.cuda()\n","\n","# model.eval()\n","# output = model(test_tensor, 1)\n","# print(output)\n","# out = F.softmax(output, 1)\n","# print(out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R_gTX2B5PZth","outputId":"9874276a-7f77-4e0f-86ea-3c21830462a5","colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["plt.plot(train_acc_history, label='Training Accuracy')\n","plt.plot(val_acc_history, label='Validation Accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}